 
 
Study Title: Evaluation of a Crowd- Powered Web Platform for Depression and Anxiety  
 
Study ID: [REMOVED] 
 Document Date:  January 14, 2021   
 
 
Objectives :  
 
This pi[INVESTIGATOR_250845]- Powered Platform on 
symptoms of depression and anxiety and evaluate whether the platform engages the putative targets 
of personal relevance and interpersonal relationship building, resulting in increased skills mastery and skills use. We will enroll 100 participants in a two- armed randomized controlled trial of the platform. 
Participants will be randomly assigned to receive either the crowd- powered platform (treatment) or a 
similar self -guided platform (control) that contains the didactic material (learning) but none of the 
crowd features. Participants will be recruited from Mental Health America (MHA)'s Screening- to-
Supports platform, an online screening platform that conducts approximately 3000 screens each day. The MHA Screening- to-Supports platform includes screeners for depression (PHQ -9) and anxiety 
(GAD -7). Individuals who screen positive for depression or anxiety will receive brief online study 
advertisements. Study advertisements will be 1- 2 sentences long, and include the following text: 
“Click here to take part in a [ADDRESS_305067] a new online platform for depression and 
anxiety”. Individuals who receive and click on these advertisements will have access to a REDCap form with screening questions regarding demographics, contact [CONTACT_3031], age, diagnostic status and English proficiency. Those who are eligible as determined by [CONTACT_250847] a 1 hour remote interview where they will 1) review the consent form with research staff and electronically sign via REDCap’s e- consent form 2) complete a 
diagnostic assessment with modules of the SCID. Afterward, participants will be sent a REDCap link via email to complete baseline assessments and will receive login information for their assigned platform (e.g., treatment or control) via email. Participants will use their assigned platform for [ADDRESS_305068] 3 times per week. Participants will be sent weekly newsletters via Mailchimp.com, and text message reminders to complete surveys. These newsletters will include didactic information about the platform and platform content, reminders to engage with the platform, and reminders to complete study measures. Participants will receive trial assessments at baseline, week 4, and week 8 (post -treatment). Follow -up evaluations will occur at 16 weeks to 
evaluate maintenance of gains. In addition, a subset of participants will be asked to complete a one-hour evaluation of user experience at 16 weeks.
 
 
Design:  
100 participants will be enrolled in a two- armed randomized controlled trial of the ADAPT platform. 
Participants will be randomly assigned to receive either the ADAPT platform (treatment) or a similar 
self-guided platform (control) that contains the didactic material (learning) but none of the crowd 
features (requesting or responding). Participants will use their assigned platform for a treatment period of 8 weeks. Participants will receive trial assessments at baseline, week 4, and week 8 (post -
treatment). Follow -up evaluations will occur at 16 weeks to evaluate maintenance of gains.  
 Methods : 
 Participants will be asked to interact with their assigned platform for [ADDRESS_305069] emails will be deleted 
from Mailchimp. Participants will also complete a series of online surveys that will ask questions about their mental health, which will begin at the time of enrollment, and will be administered at 4 weeks, 8 weeks, and 16 weeks. Participants will receive text message reminders to complete surveys when they are received. Text message reminders will say the following: “Hello, this is a reminder from the Overcoming Thoughts Study to complete your [week 4, 8, 16] surveys. You must complete all surveys in order to receive the maximum payment. (These are very important to our research and we appreciate your time.) If you have any troubles, please contact [CONTACT_3019]. Thank you!” At [ADDRESS_305070] a 25% improvement from pre- treatment score on the DASS and a shift in 
category (e.g., moderate to mild). Interviewers will be blind to treatment condition as well as benefit and usage status. Each self -report assessment and remote interview will take approximately one 
hour. The total time required for each participant (including time spent on platform, 4 self -report 
assessments, and bot h possible remote interviews) is 10 hours.  All remote interviews will be audio 
recorded for analysis and quality assurance. Researchers will gather usage data directly through the platform, such as number of log- ins and length of use per session.  
“Crowdu ser” information refers to all user -generated responses submitted on the platform, which are 
subsequently visible to all other users accessing the site. The crowdsourced platform is publicly available on Mental Health America’s website, therefore participants in the crowdsource condition may see content submitted by [CONTACT_105]- study participants. Information submitted by [CONTACT_250848] (non-
participants) will not be gathered and included in the data report that UCI researchers receive. Only data gathered from the  consented participants will be gathered for study purposes.  
 
Feasibility metrics  will also be drawn from data collected through the ADAPT platform including the 
amount of time required to produce an acceptable response to a request,  amount of time between 
notifications being sent to a user and their login to the platform. If professionals are required to generate some content, we will also estimate the cost of producing a response by [CONTACT_250849]. Adherence will be tracked as the number of 
days between a user’s first and last login to the ADAPT platform as well as the number of unique days that the user visited the ADAPT platform. Users will be instructed to use the platform at least 3 times a week and we will also look at the number of weeks that users meet this expected level of use (0-8).  
Acceptability will be assessed through quantitative ratings of the ADAPT platform at end of 
treatment. Additionally, we will conduct individual interviews with a subset of participants using purposive sampling to identify those who did or not benefit balancing across the treatment and control arm. Benefit will be defined as those who received at least a 25% improvement from pre- treatment 
score o n the DASS and a shift in category (e.g., moderate to mild). Interviewers will be blind to 
treatment condition as well as benefit status.  
Target Outcomes include measures of clinical symptoms, accountability, skill use and mastery, 
functioning, and use of  the platform. We will use identical measures to the field trial. An online 
administered self -report assessment will measure depressive and anxiety symptoms using the DASS, 
accountability using the SAQ, skills use and mastery using the F requency of Actions and Thoughts  
and Copi[INVESTIGATOR_170294] -Efficacy, and functioning using the PROMIS Ability to Participate in Social Roles and 
Activities Scale at baseline, week 4, week 8, and week 16. A telephone interview will consist of the SCID- 5 for depression status and anxiety status at baseline. Use metrics include nu mber of logins, 
number of times each task is completed (learning, requesting, responding), and time spent on the platform  
 
 
 
Scientific Background : 
 
Depression and anxiety are the most common mental health disorders in the [LOCATION_002] with 
estimated 12- month prevalence rates of 18.1% and 9.5% respectively. These disorders commonly 
co-occur and it is estimated that over [ADDRESS_305071], yet many people fail to receive them. Estimates of service utilization indicate that among those meeting criteria for a mental disorder nearly 80% receive no treatment whatsoever. Barriers to treatment include costs, time, access, and stigma associated with mental health treatment. In response to these barriers, many researchers and healthcare systems have turned to technology -
based treatment options, such as Internet websites and mobile apps, as alternatives to traditional face- to-face treatments. These interventions are referred to collectively as “behavioral intervention 
technologies” (or BITs) to distinguish them from other information and communication technologies that support healthcare more generally such as electronic medical records, clinical decision support programs, and telemedicine. As an alternative to traditional treatments, BITs allow users to access resources from anywhere in the world, at a time of their choosing. Various BITs for depression and anxiety have been evaluated with evidence supporting their efficacy. This includes Internet websites and mobile applications that draw from established evidence- based treatments such as cognitive-
behavioral therapy (CBT), or transdiagnostic approaches. Despi[INVESTIGATOR_75159], one of the primary challenges that BITs face is sustained engagement. Open access BITs have particularly low rates of adherence with several studies finding only 1% of users complete all modules. Engagement tends to be better in clinical trials of BITs, with a systematic review finding completion rates ranged from 12-100% with a median of 56%. One  characteristic that differentiated those trials with higher completion 
rates from those with lower completion rates was the use of human supported BITs. Completion rates in human supported BITs were found to be 80%, which compares favorably to face- to-face treatment. 
We think human support matters because it increases personal relevance of the techniques contained within the BIT and increases accountability. In traditional face- to-face CBT, the techniques 
factor refers to a therapi[INVESTIGATOR_541]’s fidelity to evidence- based practices while also acknowledging that 
adaptations must be made for each individual. In BIT treatments, fidelity to evidence- based principles 
can be very high, as it is pre- programmed. Most BITs, however, are not adapted for an individual and 
their needs. As such, we suggest that increasing the personal relevance within BIT treatments may 
increase skills use, mastery, and ultimately functioning. Personal relevance can be increased by [CONTACT_250850] a person’s daily life. Human support also increases relational factors. In traditional face- to-face CBT, relational factors refer to the general qualities of the interaction between 
patient and therapis t, and the therapi[INVESTIGATOR_541]’s ability to be attuned to their patients. In BIT treatments, 
relational factors have been most often described through the model of supportive accountability. In short, personally relevant therapeutic techniques and accountability dri ve skills use and mastery. 
Increased skills use and mastery results in improved functioning and clinical outcomes. Indeed, a robust literature links CBT skills use and mastery to outcome in therapy. Less research has evaluated what factors increase skills use, but BIT treatments provide a unique opportunity to explore this in detail through their ability to systematically collect data regarding skills use. This conceptual model helps illustrate why BITs that include human support have higher rates of engagement and greater efficacy. In order for BITs to reach their potential of offering scalable accessible interventions, novel strategies are needed to leverage non- professionals to support treatment engagement. This project 
explores enhancing BITs through crowd -powered processes. Crowdsourcing has been used in 
several successful technologies (e.g., reCAPTCHA, Foldit). At its core, crowdsourcing is a method for rapi[INVESTIGATOR_250846] a larger scale. For effective 
 
 
crowd work, tasks need to be decomposed and distributed such that each person’s contribution 
advances the overall goal of the task. This is possible through structuring intervention content into 
discrete steps that are consistent with evidence- based treatment strategies. In this project we will 
evaluate the effectiveness of a crowd- powered treatment for depression and anxiety. The platform will 
contain structured modules that provide scaffolded instructions for evidence- based treatment 
strategies (i.e., behavioral experiments and cognitive restructuring) and will support these processes through crowd- interactions. Users of the platform can perform [ADDRESS_305072] tasks: (1) learning, (2) 
requesting, and (3) responding. Learning involves reading didactic content, reques ting involves 
completing interactive forms based on the selected treatment strategies, and responding involves interacting with requests submitted by [CONTACT_250851]. Each user can perform all of these tasks, however, they will be made available on the platfor m sequentially after each user successfully 
completes prior tasks. Therefore, users are not assigned to roles from the start but rather will learn, request, and respond at different times. It has been noted that individual psychotherapy as the dominant model of treatment delivery is unlikely to meet the need for mental health services. Instead, we need novel delivery models leveraging new opportunities like technology. The future of BITs for mental health need to include interventions that are as engaging as Facebook and Twitter but as efficacious as the best evidence- based practices developed through years of psychological research. 
The aim of the current platform is to achieve this goal through combining evidence- based treatment 
strategies and peer interactions to create a system capable of refining these evidence- based 
strategies and personalizing mental health interventions.
 
 