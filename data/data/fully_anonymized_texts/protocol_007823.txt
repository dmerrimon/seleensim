      Interpretation Training to Reduce Anxiety: Evaluating Technology-based Delivery Models and Methods to Reduce Attrition  Study Protocol and Statistical Analysis Plan  [STUDY_ID_REMOVED]  May 24, 2023                                 

PREREGISTRATION  1  Web-Based Interpretation Bias Training to Reduce Anxiety: A Sequential, Multiple-Assignment, Randomized Trial  Metadata  Contributors  Katharine E. Daniel, Jeremy W. Eberle, and Bethany A. Teachman  Description  This is an initial pre-registration for a sequential, multiple assignment, randomized trial testing the target engagement and effectiveness of an online interpretation bias training intervention in a geographically diverse, anxious, treatment-seeking sample.   Registration Type  OSF Preregistration   Date Registered  December 2, 2020   Date Created  December 2, 2020   Study Information  Hypotheses  This sequential, multiple assignment, randomized trial (SMART) was pre-registered at clinicaltrials.gov (https://clinicaltrials.gov/ct2/show/[STUDY_ID_REMOVED]) and was designed to test the target engagement and effectiveness of an online interpretation bias training intervention in a geographically diverse, anxious, treatment-seeking sample. Further, this study aims to investigate whether adding minimal human contact [CONTACT_275208]. Here we pre-register the following hypotheses:   Interpretation Bias and Anxiety Hypotheses  A cognitive style characterized by [CONTACT_275209], negative interpretations of ambiguous situations has been associated with anxiety-related pathology (Beard, 2011). Cognitive bias modification for interpretations (CBM-I) is an online cognitive training intervention that aims to reduce symptoms of anxiety by [CONTACT_275210] (Hallion & Ruscio, 2011). We will test the effectiveness of the CBM-I intervention on measures of target engagement (i.e., interpretation bias) and measures of anxiety severity. We expect that 
PREREGISTRATION  [ADDRESS_336022]-treatment (where post-treatment is measured immediately following session 5). We also expect that treatment gains will be maintained for individuals assigned to CBM-I (vs. psychoeducation) at two-month follow-up. When comparing outcomes within the three CBM-I arms of the study, we expect the high-risk for attrition plus telecoaching group to show greater increases in positive interpretation bias and greater reductions in negative interpretation bias and anxiety symptoms compared to the high risk for attrition group who were not randomized to receive telecoaching. Comparisons between the low risk for attrition group and the high risk for attrition groups (with or without telecoaching) are of secondary interest and these hypotheses are non-directional.  Treatment Dropout Hypotheses  Online mental health interventions have long-been plagued by [CONTACT_275211] (Eysenbach, 2005). Therefore, it is important to investigate whether adding minimal human contact (i.e., providing telecoaching) to participants identified as being at high risk for treatment dropout improves retention in this online intervention trial. We expect that CBM-I participants identified as being at high risk of treatment dropout who were randomized to receive a supplemental telecoaching intervention will drop out at a later session than high risk CBM-I participants who did not get randomized to the telecoaching intervention. Further, we expect that the three CBM-I arms of the trial will be associated with less attrition than the psychoeducation comparison group.  Notably, participants were not randomly assigned to their high- or low-risk status, so causal inference between the high and low risk CBM-I groups is unsupported by [CONTACT_275212]. However, we expect that participants identified as being at high risk of treatment dropout but who did not receive the telecoaching intervention will show earlier treatment dropout than CBM-I participants identified as being at low risk for attrition. As a secondary analysis, we will also compare treatment dropout between low risk CBM-I participants and those high risk CBM-I participants who received the additional telecoaching intervention to test whether or not the supplementary telecoaching intervention appears to buffer against the risk of early dropout. However, this hypothesis is non-directional.   Design Plan  Study Type  Experiment - A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.  Blinding  
PREREGISTRATION  [ADDRESS_336023] been assigned.   Is there any additional blinding in this study?  No response  Study Design  We recruited and enrolled 1746 anxious adults with access to a smartphone, computer, or tablet to participate in a “computer-based program to reduce anxiety symptoms.” Participants were eligible to participate if they scored at or above a 10 on the anxiety subscale of the Depression, Anxiety, and Stress Scale (DASS-AS; Lovibond & Lovibond, 1995), had access to an internet-enabled device, and were at least 18 years of age.  Enrolled participants who completed readiness rulers and demographics questions at pretreatment were randomly assigned to either complete five 15-minute cognitive bias modification for interpretations (CBM-I) training sessions with 40 scenarios per session or to a psychoeducation condition according to a 75:25 stratified randomization ratio schedule. Participants were instructed to complete one training session per week over the course of five weeks and were instructed to complete these online training sessions using their preferred internet-enabled device (i.e., participants could opt to use multiple devices or to use the same device throughout the five-week training).  Immediately following the assessment administered after the first of five training sessions, participants initially randomized to the CBM-I condition were identified as being either at high or at low risk for treatment dropout using an algorithm based on theoretically- and empi[INVESTIGATOR_3675]-derived individual characteristics (e.g., age, symptom severity) and on qualities of their performance throughout the first training session (e.g., duration of web page views). Participants identified as being at high-risk for treatment dropout were randomly assigned according to a 50:[ADDRESS_336024] intervention (telecoaching) or to continue without change with the standard CBM-I condition. Participants identified as being at a lower risk for droppi[INVESTIGATOR_275202]-I intervention.  Using this sequential, multiple assignment, randomized trial (SMART), we are able to compare the four treatment arms of this study on measures of anxiety severity, target engagement (interpretation bias), and attrition/adherence. The four treatment arms are: (1) CBM-I low risk for dropout, (2) CBM-I high risk for dropout with telecoaching added after session 1, (3) CBM-I high risk for dropout with no telecoaching added, and (4) psychoeducation throughout. Further, we will be able to test whether the trajectories of anxiety symptoms and attrition change differentially over time for study arms 3 and 4 after high-risk identification and subsequent randomization to either telecoaching or no change.  • Study Flow.png  • Detailed Study Flow.png  
PREREGISTRATION  4  • Detailed Study Flow Key.png   Randomization  The randomization scheme is detailed under the study design section of this pre-registration and is illustrated in the attached figures. Note that there are two points of randomization within this SMART design, the first according to a 75:25 ratio (where the majority of participants are randomized to the CBM-I intervention vs. the psychoeducation condition) and the second according to a 50:50 ratio (where this randomization is only applied to those participants in the CBM-I condition identified as being at high risk for dropout). Both randomization schemes were stratified based on self-reported gender and anxiety symptom severity at baseline.  The above randomization scheme was specified to ultimately yield equal cell sizes for each of the four conditions (i.e., 25% of randomized subjects in each). However, as of 10/28/2019, the four cell sizes were imbalanced (ranging from 15.9% to 25%) due to a large number of CBM-I subjects not completing Session 1 after Stage 1 randomization to the CBM-I arm of the intervention. Importantly, completed Session 1 measures were needed for the attrition algorithm to be able to classify CBM-I subjects as high or low risk of dropout before Stage 2 randomization could be applied to high risk subjects. Thus, to reduce the imbalance in the number of subjects randomly assigned to each of the four groups across both stages of randomization, we changed the allocation at Stage 1 randomization on 10/31/2019 from 25% Psychoeducation and 75% to CBM-I to 10% and 90%, respectively.   Sampling Plan  Existing Data  Registration prior to analysis of the data  Explanation of Existing Data  We registered the overall project and identified primary outcomes at clinicaltrials.gov (https://clinicaltrials.gov/ct2/show/[STUDY_ID_REMOVED]) prior to data collection. However, this pre-registration through OSF is occurring after data collection but prior to any data analysis. This pre-registration represents the first set of substantive analyses proposed in this dataset. To date, these data have only been viewed by [CONTACT_275213] (i.e., that we are succeeding in recruiting a diverse sample). We also regularly reported attrition updates by [CONTACT_275214] (i.e, to catch duplicate entries). Data cleaning is currently ongoing by [CONTACT_275215].   Data Collection Procedures  Intervention sessions were administered and data were collected through the established MindTrails website. Enrollment was open to an international sample of anxious adults (inclusion 
PREREGISTRATION  5  criteria listed in the study design section of this registration). Participants were recruited through postings on online newsletters, research websites, mental health forums, Craigslist, social media (e.g., Facebook, Instagram, Twitter, Reddit), and UVA student group listservs; flyers posted in the Charlottesville community and at UVA and other nearby [CONTACT_275216]; news sources (e.g., articles, radio interviews, podcasts); and Google Ads. In addition, to improve recruitment of underrepresented groups, we sent emails to a market research firm's database of participants who self-identified with anxiety or depression and as Black/African American, Hispanic/Latinx, or Asian; we also posted in an online newsletter for multicultural student services at UVA. Note that participants may have presented to the Mindtrails website starting on 3/12/[ADDRESS_336025] to combine all participants in this initial investigation of the major aims of this clinical trial.  Per protocol, after enrollment and informed consent was obtained, each participant completed a pre-treatment assessment battery, one training session per week over the course of five weeks, comprehensive assessment batteries immediately following training sessions 3 and 5, and a follow-up assessment battery two months after training ended. Participants also completed a shorter schedule of assessments after training sessions 1, 2, and 4 to reduce participant burden.  Participants were compensated via e-gift cards according to the following payment schedule. Participants were awarded $5 per assessment battery completed at pre-treatment, after session 3, and after session 5. Participants were further awarded $10 for completing the 2-month follow-up assessment, amounting to a total possible compensation of $25 in e-gift cards distributed by [CONTACT_275217].  No files selected   Sample Size  Per protocol, we planned to recruit and enroll 1,000 highly anxious individuals and sequentially employ a series of weighted randomization rules to achieve four treatment arms (i.e., four study conditions) of approximately equal weight (approximately 250 participants per group). Data collection is now complete and we enrolled [ADDRESS_336026] training session and are considered intent to treat (ITT). At Stage [ADDRESS_336027] training session (835 in CBM-I and 240 in psychoeducation) and are included in our primary analyses. The 835 CBM-I completers of the session 1 assessments were classified as higher (n = 547) or lower (n = 288) risk of study dropout, whereas the 149 CBM-I participants who did not complete the session 1 assessments were not able to be classified as higher or lower risk of study dropout. Of the 547 CBM-I participants classified as higher risk of study dropout, at Stage 2 randomization 282 were assigned to receive coaching and 265 were assigned to no change. In total, 559 of the 1238 ITT participants completed five training sessions and are deemed treatment completers.  
PREREGISTRATION  6  Sample Size Rationale  Prior to data collection, we conducted an analysis of variance (ANOVA) to estimate the sample size needed to test main effects of delivery methods (i.e., phone vs. computer), human contact, and their interaction according to a 2 (phone vs. computer) x 3 (high risk: TeleCoach, high risk: continued CBM only, low risk: continued CBM only) design. While we ultimately decided to not randomize participants to CBM-I delivery platform (to prioritize participant preference to maximize engagement and minimize burden), our initial power analysis assumed small to medium effects for this 2x3 design. In this power analysis, we elected to be conservative due to the SMART design yielding unbalanced cell sizes. Further, given that the second stage of randomization is based on performance in the earlier stage, we were unable to determine what an effect size might be in advance. With our assumed effect size (d = .35, f = .175), to have 80% power, we would need n = [ADDRESS_336028]. However, given that we expected high rates of attrition, we assumed a 66% dropout rate (based on previous attrition rates on our MindTrails cite), so we multiplied n = 240 by 3 [i.e., 1/1-.66)], resulting in N = 720. For the psychoeducation comparison condition, we elected to match the sample size to the expected final cell size for the three other conditions (i.e., n = 120). We did not scale up the condition sample size given the SMART design does not split the control condition in a second stage of randomization.   Stoppi[INVESTIGATOR_275203] a selected date. Data collection began on 3/18/2019. We analyzed data collected through 11/27/2020.   Variables  Manipulated Variables  There were two stages of randomization throughout the SMART (described elsewhere in this pre-registration).   No files selected   Measured Variables  Interpretation Bias (Target Engagement)  1) Recognition Ratings for Measuring Change in Interpretation Bias (modified from Matthews & Mackintosh, 2000). To measure negative and positive interpretation bias, participants were asked to complete the recognition ratings measure (modified from Matthews & Mackintosh, 2000) at pre-intervention, after session 3, after session 5, and at the 2-month follow-up. Participants were presented with nine ambiguous stories and were asked to imagine themselves in each of those nine situations. The final word of each story was presented as a word fragment and participants were asked to complete the final word to disambiguate the scenario. Participants were then asked to complete a comprehension question tied to each story’s 
PREREGISTRATION  7  resolution. After completing all nine stories, participants were presented with the title of each story, four alternative disambiguated interpretations per story, and were asked to rate how similar each of the four interpretations were to the original story’s resolution using a scale ranging from 0 (“very different”) to 3 (“very similar”). Participants also had the option to select Prefer Not to Answer. Two of the disambiguated interpretations provided per story were threat-related (one negative, one positive/benign) and two were threat-unrelated (one negative, one positive/benign). Endorsements of threat-relevant negative disambiguated interpretations are averaged across all nine stories to compute the negative interpretation bias score, where higher scores reflect a greater negative interpretation style. Endorsements of threat-relevant positive/benign disambiguated interpretations are averaged across the nine stories to derive the positive interpretation bias score, where higher scores reflect a greater positive interpretation style.  2) Brief Body Sensations Interpretations Questionnaire (BBSIQ; modified from Clark et al., 1997). To measure negative and positive interpretation bias using an approach less tied to the intervention’s procedure, participants were asked to complete the Brief Body Sensations Interpretations Questionnaire (BBSIQ; modified from Clark et al., 1997) at pre-intervention, after session 3, after session 5, and at the 2-month follow-up. To complete the BBSIQ, participants were presented with [ADDRESS_336029] occurred (where two explanations are benign and one explanation is anxiety-congruent) using a 0 (“not at all likely”) to 4 (“extremely likely”) Likert scale. Participants also had the option to select Prefer Not to Answer. The negative interpretation bias score is computed by [CONTACT_275218]-congruent explanations, such that higher scores reflect a greater negative interpretation style, whereas the positive interpretation bias score is computed by [CONTACT_275219], such that higher scores reflect a greater positive interpretation style.  Anxiety Symptoms  1) Overall Anxiety Severity and Impairment Scale (OASIS; adapted from Norman, Cissell, Means-Christensen, & Stein, 2006). To measure subjective evaluations of the frequency and severity of anxiety, avoidance, and associated impairment, participants completed the five-item OASIS (Norman et al., 2006). All items are rated on a scale of 0 (lowest impairment/severity) to 4 (highest impairment/severity). Participants also had the option to select Prefer Not to Answer. The OASIS was assessed at all time points (pre-intervention, after all five sessions, and at two-month follow-up).  2) Depression, Anxiety, Stress Scales-Short Form - Anxiety Subscale (DASS-AS; adapted from Lovibond & Lovibond, 1995). To assess eligibility to enroll in the study and to measure participants’ subjective evaluations of the frequency of their anxiety symptoms since their last training session, participants completed the seven-item DASS-AS using the response scale 0 (“not at all”) to 3 (“most of the time”), where higher scores indicate greater symptom severity. Participants also had the option to select Prefer Not to Answer. Participants completed this questionnaire at pre-screener, after session 3, after session 5, and at 2-month follow-up.   No files selected  
PREREGISTRATION  [ADDRESS_336030] CBM-I SMART design. As such, we will use uninformative priors in these estimations.  Due to the study’s SMART design, we will employ a pi[INVESTIGATOR_275204]. Doing so will allow us to minimize the bias that a simple linear mean trajectory would otherwise impose by [CONTACT_275220]-randomization (Nahum-Shani et a., 2019). In a pi[INVESTIGATOR_59776], a separate line segment can be fit for different intervals over the course of the study, with the boundary for the time intervals forming a transition point, such as from one treatment stage to another. In the current study, we have three stages of interest: the first stage (S1) of the clinical trial (pre-treatment to re-randomization point after session 1); the second stage (S2) of the clinical trial (session 2 to session 5); and the third, or follow-up, stage (S3) of the clinical trial (session 5 until two months later). With a pi[INVESTIGATOR_275205], the linear trend in the outcome during the first stage can be allowed to vary from the linear trend during the second and third stages, and to be impacted by [CONTACT_275221]. We will assume the same intercept for all four treatment arms because, by [CONTACT_8345], treatment arms are not expected to differ at baseline. We will assume that the marginal mean trajectory between the [ADDRESS_336031] accommodate features of the SMART design itself (Nahum-Shani et al., 2019), we will code time using three variables constructed in the manner outlined in Pre-registration Table 1.  
PREREGISTRATION  9  
  Further, to code treatment condition for the four treatment arms in line with methods described by [CONTACT_275222] (2015) and Nahum-Shani and colleagues (2019), we will create a label of contrast codes for each of the two stages of the intervention. We elect to use contrast coding (1/-1) as opposed to dummy coding (0/1) so that we will be able to directly compare outcomes tests of regression coefficients to tests of main effects (see Collins, 2018; Myers, Well, & Lorch, 2010). Because there are two intervention stages by [CONTACT_8345] (i.e., two sequential randomization decision points), we will let (a1, a2) denote the different contrast codes we’ll test between treatment arms at both randomization stages.  Let a1 = -1 for participants initially randomized to psychoeducation and let a1 = [ADDRESS_336032] upon which to interpret our interpretation bias and anxiety hypotheses: Study arm differences in (1) average outcomes at the end of the session 5 and at 2-month follow-up (i.e., time-specific outcomes); (3) rates of change 

PREREGISTRATION  11  in outcomes between pre-intervention and session 1, between sessions 1 and 5, and between session 5 and 2-month follow up (i.e., stage-specific slopes); and (4) highest outcomes averaged across the entire course of the study (i.e., area under the curve from pre-intervention to follow-up).  Models Testing the Probability of Droppi[INVESTIGATOR_275206], we will run a logistic multilevel model with a logit link function to predict at each of the five training sessions 2-5 whether completion (0) or noncompletion (1) of the training session (without regard for whether participants completed the assessments that immediately followed the last training session they completed) varies based on treatment arm group membership. Given that no treatment occurred at the follow-up assessment, we will include only stages S1 and S2, coded as follows (Pre-Registration Table 3) from pre-intervention to Session 5. All other parameters will remain consistent with the primary outcomes model above. Treatment dropout analyses will only be run for the participants who completed at least the first training and associated assessment battery given that, by [CONTACT_108], treatment completers will have completed all five training sessions.  
  The proposed model equation is provided in Pre-Registration Equation Set 2.  

PREREGISTRATION  [ADDRESS_336033] upon which to interpret our treatment dropout hypotheses: Study arm differences in (1) average likelihood to have dropped out during or before session 5 training (i.e., time-specific outcome of primary interest), (2) average likelihood to have dropped out during or before session 2 training (i.e., time-specific outcome of secondary interest), (3) average likelihood to have dropped out during or before session 3 training (i.e., time-specific outcome of secondary interest); and (4) average likelihood to have dropped out during or before session 4 training (i.e., time-specific outcome of secondary interest).  • Pre-Registration Table 1.png  • Pre-Registration Table 2.png  • Pre-Registration Equation Set 1.png  • Pre-Registration Table 3.png  • Pre-Registration Equation Set 2.png   Transformations  As stated above, we will center time (S1) at zero for all longitudinal models such that the pre-intervention assessment points for all participants, regardless of the date of their initial assessment, will be set to 0.  We will mean center any continuous baseline covariates (e.g., SES).   Inference Criteria  We will make statistical inferences according to obtained HPD 95% Credible Intervals.   

PREREGISTRATION  [ADDRESS_336034] been randomized to receive telecoaching or not. While excluding these participants interferes with being able to make causal claims (i.e., this is not an intent-to-treat sample), it allows for us to reduce uncertainty and error in group assignment. Since we aim to compare outcomes between groups, we have decided to prioritize accurate group assignment over an ITT sample with group classification uncertainty. As such, our primary analyses will be conducted on the 1075 session 1 assessment compeleters and our secondary completer analyses will be conducted on the participants who completed all five training sessions (whether those sessions were composed of psychoeducation or CBM-I). To be considered a completer within the high-risk plus telecoaching group, those participants must also have engaged with a telecoach at least once.   Missing Data  The present data likely exhibit two missing data patterns. At the item level, participants had the option to select Prefer Not to Answer when completing RR, the BBSIQ, the OASIS, and the DASS-AS, likely resulting in a general missing data pattern when they did so. In such cases, which we expect to be rare, we will analyze the mean of the available items.  At the scale level, we expect attrition to yield a monotone missing data pattern. To find any measured variables that may relate to this pattern of missing data and that are not already included in the analysis models, we will test whether demographics, training confidence, change importance, and device use correlate with binary indicators of scale-level missingness at each time point given that analyses of missingness in prior MindTrails studies have found that these variables predict missingness (e.g., Eberle et al., 2020; Hohensee et al., 2020). Following an inclusive analysis strategy (Collins et al., 2001), we will include any variables that correlate with missingness at greater than |.40| (which Enders, 2010, p. 133, states is the correlation yielding the “most useful” auxiliary variables) as auxiliary variables in our Bayesian analyses to correct for any systematic bias resulting from these variables’ relationships with missingness.  Exploratory Analysis  No response  Other  References  Beard, C. (2011). Cognitive bias modification for anxiety: current evidence and future directions. Expert Rev Neurother, 11(2), 299–311. https://doi.org/10.1586/ern.10.[ADDRESS_336035], L. G., Breitholtz, E., Koehler, K. A., Westling, B. E., & Gelder, M. (1997). Misinterpretation of body sensations in panic disorder. Journal of Consulting and Clinical Psychology, 65, 203-213.  Collins, L. M. (2018). Optimization of behavioral, biobehavioral, and biomedical interventions: The multiphase optimization strategy (MOST). Cham, Switzerland: Springer.  Collins, L. M., Schafer, J. L., & Kam, C-M. (2001). A comparison of inclusive and restrictive strategies in modern missing data procedures. Psychological Methods, 6, 330-351. https://doi.org/10.1037/1082-989X.6.4.330  Eberle, J. W., Boukhechba, M. O., Sun, J., Zhang, D., Funk, D. H., Barnes, L. E., & Teachman, B. A. (2020). Shifting epi[INVESTIGATOR_275207]: A randomized controlled trial. Preprint under review. PsyArXiv. http://doi.org/d54p  Enders, C. K. (2010). Applied missing data analysis. Guilford press.  Eysenbach G. (2005). The law of attrition. Journal of medical Internet research, 7(1), e11. https://doi.org/10.2196/jmir.7.1.e11  Hallion, L. S., & Ruscio, A. M. (2011). A Meta-Analysis of the Effect of Cognitive Bias Modification on Anxiety and Depression. Psychological Bulletin. https://doi.org/10.1037/a0024355  Hohensee, N., Meyer, M. J., & Teachman, B. A. (2020). The effect of confidence on dropout rate and outcomes in online cognitive bias modification. Journal of Technology in Behavioral Science. https://doi.org/10.1007/s41347-020-[ZIP_CODE]-8  Lovibond, P. F., & Lovibond, S. H. (1995). The structure of negative emotional states: Comparison of the Depression Anxiety Stress Scales (DASS) with the Beck Depressionand Anxiety Inventories. Behaviour Research and Therapy, 33(3), 335–343.https://doi.org/10.1016/0005-7967(94)[ZIP_CODE]-U  Lu, X., Nahum-Shani, I., Kasari, C., Lynch, K. G., Oslin, D. W., Pelham, W. E., … Almirall, D. (2016). Comparing dynamic treatment regimes using repeated-measures outcomes: Modeling considerations in SMART studies. Statistics in Medicine, 35(10), 1595–1615. https://doi.org/10.1002/sim.6819  Mathews, A & Mackintosh, B. (2000). Induced emotional interpretation bias and anxiety. J Abnorm Psychol; 109(4):602-15.  Myers, J. L., Well, A., & Lorch, R. F. (2010). Research design and statistical analysis (3rd ed.). [LOCATION_001], NY: Routledge.  
PREREGISTRATION  15  Nahum-Shani, I., Almirall, D., Yap, J. R. T., McKay, J. R., Lynch, K. G., Freiheit, E. A., & Dziak, J. J. (2019). SMART longitudinal analysis: A tutorial for using repeated outcome measures from SMART studies to compare adaptive interventions. Psychological Methods, 25(1), 1–29. https://doi.org/10.1037/met0000219  Norman, S.B., Cissell, S.H., Means-Christensen, A.J., & Stein, M.B. (2006). Development and validation of an Overall Anxiety Severity and Impairment Scale (OASIS). Depress & Anxiety; 23(4): 245-9. https://doi.org/10.1002/da.[ZIP_CODE]. PMID: 16688739.   