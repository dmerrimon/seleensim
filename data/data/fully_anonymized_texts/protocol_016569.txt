 
Pediatric Anxiety Intervention With an Entertaining Video 
Game: Feasibility Study  
 
ID: 14 -000162  
 
[STUDY_ID_REMOVED]  
 
March 14, 2019 
  
Prototype Evaluation  
 
Each child -parent pair participated in in a single (up to) 3 -hour visit, allowing for breaks  
as needed. Staff from Mayo Clinic HealthCare Policy & Research experienced in qualitative data 
analysis and not involved with the patients’ medical care or development of the video game  
conducted the study visits. During the first 15 minutes the children and parents were 
introduced to the rationale for the feasibility study, completed IRB -approved informed consent 
and assent  procedures, and were provided a brief description of exposure therapy and the 
game’s intended  purpose to facilitate children’s engagement in social exposures. Next, the 
children were told that they would have the opportunity to earn additional time to play the 
game if they chose to give a 30-second speech to a co -worker of the interviewer following the 
initial game -play period.   Children were asked  to rate their nervousness about giving the speech 
on a visual subjective  rating -of-distress (SUD) scale (0 = “Relaxed, no anxiety” to 10 = “Most 
anxiety ever”) and  whether they thought would choose to give the speech (yes/no). Next, 
children interacted with  the game for up to 30 minutes while the interviewer observed and 
recorded the child’s  interaction with the game. After the initial game play time, children were 
asked to rate their  anxiety about giving the 30 -second speech using the same scale (0 -10) an d 
whether they chose to  give the speech for additional game time. If the child declined the 
speech opportunity, the  interviewer proceeded directly to the qualitative interview portion of 
the visit. If the child opted to give a speech, the interviewer stepp ed out of the room while the 
child started planning the  speech with the parent and, on returning, stated that the co -worker 
could not be found. The child was then directed to give the speech to the interviewer and was 
allowed additional time to play  the ga me. 
The final portion of the session consisted of a semi -structured interview. The semi -
structured  guide followed guidelines for minimizing bias and increasing the reliability and  
validity of interview data [65,66]. All interviews were audio -recorded. Firs t, children and 
parents  learned more about the vision for the full version of the game including concepts for 
additional  levels and linking unlocking levels to completion of real -life exposures. Next, children 
were  asked to rate how much the game would hel p them complete exposures (0 = “The game 
would  make it harder,” 5 = “no difference,” 10 “The game would make it easier”), their 
preference for  completing exposures with or without the game (0 = “without the game,” 5 = 
“no difference,” 10  = “with the game”) , and how much exposure practice they would complete 
with versus without  the game (0 = “much less,” 5 = “no difference,” 10 = “much more”). Parents 
were asked to rate  how much the game would help them and their child complete exposures (0 
= “much less,” 5 =  “no difference,” 10 = “much more”), how much the game would motivate 
their child to complete  exposures between therapy appointments (0 = “The game would be a 
distraction,” 5 = “no  difference,” 10 = “the game would motivate my child”), and how much 
they would pay for a  complete game with 10 -15 levels with an open -ended question followed 
by a multiple -choice  question with graduated pricing options. Both children and parents were 
asked to comment on  what could make the game better, how they would use the ga me, their 
overall opi[INVESTIGATOR_76645], , likelihood of recommending the game, and thoughts about doing 
exposure therapy in  relation to the game.  
 
Analyses  
Quantitative analyses included calculation of descriptive statistics for children’s and  
parents’ ratings of the game’s usefulness for exposure therapy, changes in children’s ratings of 
anxiety and willingness to complete a real life exposure from before to after playing the game  
prototype, and parents’ reported willingness to pay for the game.    
For qualitative data analyses, analysts with experience in qualitative data analysis  
identified themes, developed a coding strategy, and then coded interviews using methods of  
content analysis, i.e., systematic process of sorting and coding information based on the mes 
[64,67]. QSR's NVivo 9 (QSR International, Doncaster, Victoria, Australia; NVivo 2010)  
qualitative data software analysis program was used to facilitate data coding and sorting.  