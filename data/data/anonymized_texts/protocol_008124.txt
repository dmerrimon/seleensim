Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
 
 
 
 
 
 
 
 
Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and 
Literacy  
 
René Gifford, PhD  
Stephen Camarata, PhD  
Vanderbilt University  Medical Center  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
 
 
 
 
 
 
 
 
 
 
 
Table of Contents:  
 
Study Schema  
1.0 Background  
2.0 Rationale and Specific Aims  
3.0 Inclusion/Exclusion Criteria  
4.0 Enrollment/Randomization  
5.0 Study Procedures  
6.0 Reporting of Adverse Events or Unanticipated Problems involving 
Risk to Participants or Others  
7.0 Study Withdrawal/Discontinuation  
8.0 Priva cy/Confidentiality Issues  
9.0 Follow -up and Record Retention  
 
 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
1.0 Background   
 
This is the history of the problem/disease, and why it is important to study this particular 
problem/disease.  Discuss how this affects the target po pulation, how many are affected.  
 
(Study Purpose and Description – Brief Abstract of the Study)  
 
Although the recent literature has indicated that children receiving cochlear implants (CIs) often 
have dramatically improved speech and language ability relative to previous generat ions of 
children with hearing loss, many pediatric CI recipients display persistent speech and language 
disorders despite early implantation and associated speech/language intervention. There is a 
striking paucity and ongoing need for studies that systemat ically examine the relationship 
between intracochlear electrode location, audiological profile, and subsequent phonological 
awareness, speech, language, and literacy in pediatric CI recipients. This project provides a 
unique opportunity to examine whether individualized, image -guided CI programming 
(IGCIP) significantly improves outcomes in pediatric CI patients. The proposed research 
activities will examine the impact of personalized IGCIP in pediatric CI recipients on measures of 
basic auditory function (spectral  and temporal resolution), word and non -word recognition, 
speech production, language, phonological awareness, and reading comprehension using a 
double blind, waitlist control randomized clinical trial (RCT) design. A total sample of 72 c hildren 
with CIs aged 4.5 to 6years old will be enrolled in the project: half (n = 36) will be randomized to 
an immediate IGCIP condition and half to a waitlist control condition. The waitlisted participants 
(n = 36) will undergo IGCIP after 12 months of m onitoring and then followed for an additional 12 
months after intervention (total time in the study for both groups: 24 months). Those 
immediately provided with IGCIP will also be followed for a total of 24 months. All participants 
will undergo extensive a udiological assessment as well as tests of phonological awareness, 
speech, language, and literacy at baseline as well as at regular intervals: 2, 6, 12, 14, 18, and 24 
months. We will use predictor analyses to determine the impact of immediate and deferred  IGCIP 
on subsequent auditory, speech, language, and literacy outcomes.  
 
 
2.0 Rationale and Specific Aims   
 
This is the “why” this study is important to conduct and what you plan to do.  
 
(Study Purpose and Description – How this study adds to the knowledge on this 
topic)  
 
A. Introduction - Statement of Problem  
 
Although children with cochlear implants (CIs) have significantly improved speech, language, and 
reading outcomes relative to previous generation CI recipients, too many pediatric CI users s till 
display persistent speech, language, and reading difficulties despite early implantation and early 
intervention [see (5–7)]. Children with CIs typically lag behind their peers with normal hearing 
(NH) by 1 or more years on measures of speech, language and/or reading [e.g., (8–15)]. Though 
these persistent delays can be attributed in part to a period of auditory deprivation prior to inclu 
(12,16,17) , increasing evidence suggests that a degraded CI signal is also implicated in poorer 
development of auditory, speech, language, and reading skills  for pediatric CI recipients (6,18–
22). A related developmental path to reading also disrupted from the degraded CI signal i s 
phonological awareness (PA) because PA is predicated, in part, on speech recognition (23).   
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
     A procedure developed by Noble and colleagues (4,24 –26), image -guided CI 
programming (IGCIP), significantly improves auditory function, speech recognition, and 
distally, receptive language abilities for adult CI users. We have preliminary evidence that 
pediatric CI recipients also significantly benefit from IGCIP  (4). But there is a need to 
systematically investigate IGCIP in children to determine whet her this individualized intervention 
yields a) associated benefits in auditory function and b) related improvements in speech, 
language, PA and/or reading. Thus, our primary goal is to evaluate the effects of  IGCIP 
on auditory function, speech recognition,  PA and reading, as well as speech and 
language abilities in pediatric CI recipients within the context of a double blind, 
waitlist controlled randomized clinical trial (RCT). We will obtain psychophysical estimates 
of auditory function and speech recognit ion, PA, reading, speech, and language abilities for 60 
pediatric CI users in a baseline assessment and repeated time points for 24 months to test the 
impact of IGCIP . We will examine the immediate (short -term) and longer -term effects over a 2 -
year period by comparing outcomes between groups for those randomly assigned to immediate 
(n = 30) or deferred (n = 30) IGCIP using a waitlist control study design (deferred IGCIP) . The 
initial comparison will be for immediate and deferred IGCIP groups at 2, 6, and 12  months. The 
deferred group will then receive the IGCIP intervention and both groups will be followed for an 
additional 12 months (total enrollment for 24 months).  
 
 
B. Specific Aims  & Hypotheses  
 
Specific Aims  
 
Aim 1: Auditory function. We will com pare auditory function and speech 
recognition of the immediate and waitlist control participants . Hypothesis 1a : There will 
be significant positive short -term gains (2 -6 months) in spectral and/or temporal 
resolution as  well as speech recognition —particularly in noise —for children immediately 
receiving IGCIP as compared to waitlist controls. This hypothesis will be tested by 
comparing the difference in the amount of change in scores within -subjects (pre - to post -
IGCIP ga in) between the groups (treated vs. untreated) controlling for initial scores. 
Hypothesis 1b : IGCIP gain in spectral and/or temporal resolution will significantly predict 
gain in speech recognition. This hypothesis will be tested via regression analyses of  
change in speech recognition scores on change in resolution, controlling for baseline 
values and also controlling for baseline levels of speech recognition and working 
memory.  
Aim 2: PA and reading.  We will explore the complex relationships amongst 
auditory function, speech recognition, PA, and reading ability. Hypothesis 2a:  
Differential growth  in spectral/temporal resolution and/or speech recognition will predict 
growth in PA, which in turn will pre dict mediated growth in reading. Hypothesis 2b : 
Growth in PA will be associated with amount of IGCIP benefit (gain) and will mediate 
growth in reading, which will be tested via cross -legged panel and path analyses. Note 
that testing these hypotheses is not  dependent on the outcomes of Aim 1 as  only 
variable gain in the Aim 1 measures (e.g., speech recognition) are required for aim 2 
analyses,  not a significant between -group difference for IGCIP in Aim 1.  
Aim 3: Speech and language.  We will compare pre - and post-IGCIP receptive 
and expressive language abilities and speech production of pediatric CI recipients to the 
waitlist control group. We will test these skills at various time points on standardized and 
clinical measures of 1) receptive language, 2) expre ssive language, and 3) speech 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
production (articulation and acoustic analyses) . Hypothesis 3a : There will be significant 
differences between groups for positive growth in speech and language and this growth 
will be predicted  by the relative improvement in auditory function (aim 1) from IGCIP 
while controlling for baseline levels of working memory. Hypothesis 3b : 
Spectral/temporal resolution and speech recognition and/or PA will serve as mediators  
of expressive and receptive l anguage gains and speech production gains both within 
and between groups. 3a and 3b will also be tested using mixed effects modeling and 
regression analyses to examine these “downstream” effects. Even if no between group 
differences in Aim 1 and/or Aim 2 a re seen, we will nonetheless be able to test whether 
spectral/temporal resolution, speech recognition, and/or PA  predict growth in receptive 
and/or expressive language and/or changes in speech production (including subclinical 
acoustic analyses).   
 
 
C. Bac kground and Significance    
 
Cochlear implant (CI) technology yields significant improvement in auditory 
function, speech recognition, speech production, language, reading, and overall quality 
of life for the majority of recipients. Despite such advances, p ediatric CI recipients 
continue to display significant variability in speech and language development with too 
many recipients continuing to display poor outcomes [e.g., (10,14,15,17,27 –31)]. A 
recent study of pediatric CI users brought these issues into sharp focus:  Dettman  et al. 
(2016) investigated speech recognition and language outcomes for a large cohort of 
pediatric CI recipients (n = 403) who were all educated in an inclusion classroom using 
listening and spoken language as the primary mode of communication (17). Figure 1  is 
a reproduction of data illustrating mean standard scores for language and vocabulary for 
all children upon entry into 1st grade (14). This figure displays the magnitude and 
pervasive n ature of the deficits across language measures for even the group of children 
implanted under 24 months (green bars). Indeed, all means were at least 1 standard 
deviation below the age normative range.  
Clearly, there is an ongoing need to improve language outcomes in these 
children (7). The source of delay is partially attributed to a period of auditory deprivation 
prior to implantation [e.g., (12,16) ]. However, it is 
also likely that an impoverished CI signal is 
implicated in ongoing poorer -than-normal 
devel opment on measures of auditory, speech, 
language, and reading (8,22,32) . Several 
researchers have documented extremely poor 
spectral resolution for pediatric CI users —much 
poorer than that exhibited by adult CI recipients 
(20,33 –37). Such findings suggest that pediatric CI users with prelingual deafness may 
not depend upon spectral resolution for speech recognition in the same manner as 
adults, particularly in noisy environments. Indeed Lowenstein & Nittrouer (19) recently 
demonstrated that children with hearing loss —using hearing aids and CIs —placed 
significantly less weight on spectral cues  than children with NH. In contrast, the 
children with CIs placed greater weight on amplitude cues —related to temporal 
envelope perception —as compared to  the children with NH (19). Thus, it is possible that 
young children with CIs are making use of different cues , such as those contained within 
the temp oral envelope, or spectrotemporal contrasts, both of which have been shown to 
PLS PPVT CELF5060708090100110120
language teststandard score
all CI children
CI < 24 moFigure 1
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
yield high levels of consonant recognition in NH adults (e.g., (38–41)]. Further 
investigation is warranted to investigate the relationship between spectral resolution, 
temporal resolution, and speech recognition so that we can identify the underlying 
mechanisms driving speech recognition in pediatric CI users as well as links to PA, 
reading, speech, and language abilities. Understanding the underlying mechanisms 
driving speech recognition in pediatric CI users is not only necessary for theoretical 
purposes, but this information is critical to maximize a c hild’s auditory abilities in the 
context of both CI programming and, ultimately, for speech/language/reading 
intervention . For example, if we learn that children are using different auditory cues to 
drive speech recognition —such as greater weight on tempor al vs. spectral cues —we 
could select CI stimulation parameters that best transmit a well-defined temporal 
envelope  such as high channel stimulation rates [>1500 pulses per second (42–44)] and 
removal of current steering which can introduce  fluctuations in the temporal envelope 
that are uncorrelated with the incoming signal (45). In contrast, should we find that 
children rely heavily on spectral resolution and/or spectrotemporal cues as adult CI 
recipients do, we could choose image -guided programming strategies designed to 
transmit f iner spectral detail —such as patient -specific electrode deactivation to improve 
spatial selectivity of intracochlear excitation patterns and its psychological correlate, 
spectral resolution.  
 
Image -guided CI programming (IGCIP)  
 
Our team has pioneered the use of postoperative CT scanning of CI users to 
delineate the CI electrode -neural interface and use this information to create customized 
programming maps. We refer to this process as image -guided cochlear implant 
programming (IG CIP) and here describe how it is performed. We have constructed an 
atlas based on 10 μCT scans of human cadaveric cochleae in which scala tympani (ST), 
scala vestibuli (SV), and the modiolus have been manually delineated as these 
anatomical structures are not visually identifiable on clinical CT scans. Next, on a pre -
operative clinical CT scan, this atlas is iteratively fit to the patient’s own anatomy to 
minimize the sum of the squared distance between the bony outline of the cochlea, 
which is identifiable  both on the clinical CT scan as well as via μCT. Next, a post -
operative CT scan is obtained, the centerline of the electrode array extracted, and a 3D 
model of the electrode array fit to the scan. Finally, the pre - and post -op scans are 
superimposed upon each other as the bony anatomy is consistent. The output (top 
panel, Figure 2 ) includes 3D surfaces showing the position of individual electrodes 
relative to the neural endings they are intended to stimulate in the modiolus.  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
Next, we define the electrode -to-neural interface by calculating the distance -
versus -frequency curves from the frequency mapped neural endings within the modiolus 
to each individual electrode. This is shown in the bot tom panel of Figure 2  where each 
of the colored curves represents a different electrode and shows the Euclidian distance 
from the electrode to the modiolus (ordinate) as well as the predicted frequency range of 
the modiolus (8) at that location (top abscissa). Electrodes are chosen for deactivation to 
minimize channel interaction —or spread 
of intracochlear electrical excitation. The 
premise is that such ele ctrodes would be 
providing “redundant” electrical 
stimulation for a given segment of the 
cochlea. So, by deactivating these 
electrodes, we theorize that we are able 
to reduce channel interaction which 
should increase spatial selectivity of 
intracochlear el ectrical excitation. The 
heuristic we use to achieve this is to 
deactivate as few electrodes as possible 
while producing an overall curve with 
clearly defined local minima and with 
electrodes centered on the range of 
frequencies to which they are closest. 
Following this strategy for the example 
shown in Figure 2 , we have deactivated 
electrodes 2, 3, 4, 6, 8, 10, and 16.  
 
 
Clinical significance: CI programming  
Clinical CI programming includes the mapping of incoming sound using a “one 
size fits all” approach of current limiting, frequency allocation, and stimulation of all 
electrodes. For some individuals, it is likely that these default programming methods 
provide a reasonable approximation to the patient’s individualized anatomy and 
electrode location and that activation of all electrodes yields adequate outcomes. For 
other patients —particularly those who may exhibit poorer -than-average performance, 
have atypic al cochlear anatomy , electrode dislocation , or extracochlear electrodes —a 
“one size fits all” approach will not afford the restoration of hearing that could be 
achieved had the recipient’s anatomy and intracochlear electrode positioning been 
considered. Fo r example, a recent study of 262 CI users showed that 13.4% of patients 
had at least 1 extracochlear electrode despite surgical reports of complete insertion (46). 
Active extracochlear electrodes will produce suboptimal high -frequency transmission as 
the acoustic information being transmitted to the extracochlear electrodes  will not reach 
primary auditory neurons. Thus an additional goal of IGCIP is identification of 
extracochlear electrodes —critical information needed to ensure stimulus delivery of high 
frequency speech sounds ( Figure 6  preliminary studies). Such considerations are 
particularly critical for pediatric CI users for whom audibility of high -frequency s timuli is 
central to the acquisition of auditory -based speech and language.  
Children are routinely implanted at ~12 months of age —the minimum age 
referenced by FDA labeled indications. Thus, it is the case that for the first 3 to 5 years 
Figure 2 : Software module defining electrode -to-neural 
interface in CT scans and 3D reconstruction (top panel: 
red=ST, blue=SV, and green=modiolus). Middle panel 
shows active electrodes in red. Bottom panel shows 
distance -vs-frequency curves used to deactivate 
electrodes int erfering with neighboring electrodes.  
 

Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
of CI use, we are relying on external factors for CI programming and verification of CI 
map appropriateness. Such factors include “aided” audiometric thresholds, auditory skill 
development gauged primarily via parental questionnaire, and progress on measures of 
language and  speech production. Even if a child is making progress, it is possible that 
using an individualized approach to CI parameter manipulation —capitalizing on the 
underlying hearing mechanisms driving performance as well as individualized anatomy 
and electrode location —would result in greater performance at a faster rate allowing for 
higher overall outcomes. Indeed, we have documented that pediatric CI recipients can 
derive significant benefit from IGCIP on measures of speech recognition in quiet and 
noise (4). 
Underlying mechanisms driving auditory -based speech recognition  
  For adults with NH, speech recognition is dependent upon a high degree of 
spectral resolution of the individual components of speech including resolution of 
individual and relative formant frequencies as well as rapid fo rmant transitions. Speech 
recognition —as dependent upon spectral resolution —poses a major obstacle for CI 
recipients and attempts to improve spatial selectivity  of intracochlear electrical 
stimulation (i.e. reduction in channel interaction) have resulted i n minimal improvements 
in speech recognition abilities [e.g., (47–50)]. Most attempts at improvin g intracochlear 
spatial selectively of electrical excitation patterns and subsequent improvements in 
spectral resolution, however, have investigated current focusing such as tripolar 
electrode configuration [e.g., (51–58)] for adult CI users. Attempts at limiting channel 
interaction via current focusing have resulted in programming parameters and electrode 
configurations th at significantly limit the dynamic range of electrical stimulation as well as 
significantly increase power demands for the sound processor. Such consequences 
render the applicability of these strategies clinically prohibitive.  
Spectral resolution for CI u sers is often characterized using tasks of spectral 
modulation detection (SMD) or spectral ripple discrimination (e.g., (59–62)]. Numerous 
studies have shown a significant correlation between spectral resolution with a CI and 
auditory speech recognitio n for adult CI users  (e.g., (60,63 –69)]. Furthermore, 
researchers (45,70)  have demonstrated that psychophysical measures of spectral 
resolution are more sensitive to changes in CI processing strategies and central auditory 
reorganization following implantation than traditional clinical measures of speech 
recognition (62,70) . Thus it is common for researchers to use SMD as a proxy for 
channel interaction to determine whether CI programming change s may impact this 
phenomenon. Indeed we have shown that IGCIP yields statistically significant 
improvements in spectral resolution, via SMD, in adult CI users  (24,26,49,71) . In 
contrast to these findings, pediatric CI users exhibit extremely poor spectral resolution 
and estimates of pediatric CI spectral resolution are not significantly correlated with 
speech recognition [e.g., (20,37,72,73) ] or were modestly correlated with vowel 
recognition in quiet (74). Furthermore there are conflicting reports regarding the 
relationship between listener age, age at CI, and overall spectral resolution abilities 
(20,72,74) . 
Description of underlying auditory mechanisms responsible for pediatric CI 
speech recognition is not only important for research purposes, but holds significant 
clinical relevance . To maximize outcomes for auditory function and related outcomes for 
speech, language, and literacy of our pediatric CI recipients, we must identify the 
auditory mechanisms driving speech recognition, whether those be sp ectral, temporal, or 
some combination thereof. The reason is that clinicians have access to a variety of CI 
signal coding strategies all focusing on different aspects of the incoming stimulus. For 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
example, there are current -steering strategies designed to provide greater spectral 
representation of incoming stimuli (e.g., Fidelity -120, Optima), strategies designed to 
provide temporal fine structure in the apical channels via variable rate stimulation [e.g., 
fine structure processing], and high -rate strategie s specifically designed to provide fine 
detail for temporal envelope representation at each stimulated electrode [e.g., HiRes, 
high-definition continuous interleaved sampling, and high -rate Advanced Combination 
Encoder]. Despite the known fact that adult a nd pediatric CI users demonstrate a 
significantly different relationship between spectral resolution and speech recognition 
(20,72,73) , clinical audiologists are using the same default programming strategies (i.e. 
current steering and/or low-to-mid rate stimulation) with both adult and pediatric CI users 
within a one -size-fits-all philosophy . If we determine that pediatric CI users are more 
reliant on temporal coding for speech recognition, we can adapt a clinical approach to 
provide great er representation of temporal envelope with higher channel stimulation 
rates and removal of current steering. Ideally we would develop a data driven, 
personalized plan for CI programming capitalizing on the mechanisms driving auditory -
based speech recognit ion combined with selective IGCIP channel activation to improve 
intracochlear spatial selectivity and resultant spectrotemporal resolution. Based on our 
published and preliminary data (4,20) , our hypotheses  are that IGCIP will improve 1) 
auditory function (spectral and/or temporal resolution), 2) speech recognition, and 3) 
improvements noted for spectral and temporal resolution will mediate improvements on 
measures of PA, speech production, language, and reading while controlling for 
confounds [e.g., nonverbal cognition, working memory (75–81)]. 
 
Auditory Function, Speech Recognition, PA, and Reading  
 
Researchers and clinicians have been interested in the interrelationship between 
hearing, speech recognition, speech and language skills, PA, and reading outcomes for 
more than half a century (82–84). Until recently, speech recognition, speech production, 
language, PA and reading for children with CIs have been relatively poor and all 
domains have significantly lagged behind typic ally developing peers (6,8,21,30,85 –88). 
Advances in CI technology have yielded dramatic improvements in all these domains. 
Indeed, recent reports have indicated that a number of CI recipients are trending into the 
typical range and in some cases, even into an advanced range for language and re ading 
outcomes [e.g., (10,14,15,17,21,89) ]. Despite these encouraging findings, a significant 
number of CI users continue to demonstrate relatively poor outcomes for speech, 
language, PA and/or reading. A likely explanation is that spectral resolution is strongly 
correlated with PA (90–92). Given the generally poor, but variable, spectral resolution 
abilities exhibited by pediatric CI recipients (20,72 –74), it is not surprising that both PA 
and reading skills are often poorer than typically developing children. Despite the fact 
that pediatric CI users have poor spectral resolution and below average PA, some CI 
recipients are able to approach typical levels of performance on speech, language an d 
reading achievement. One must then ask how are some children with CIs capable of 
achieving such high levels of speech recognition and ultimately high levels of 
language and reading despite poor spectral and phonological processing?  In other 
words, how ar e children with relatively poor spectral resolution able to bootstrap 
phonological decoding and subsequent reading? One explanation is grounded in lexical 
restructuring theory (93–96). Lexical restructuring theory posits that a  child initially has 
a global representation of lexical information, and thus does not require fine spectral 
detail. As a child ages, she begins to learn phonotactic structure within her native 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
language(s) and ultimately builds a more comprehensive lexicon  (97). Nittrouer and 
colleagues reported that “ Oral language skills explained more variance in emergent 
reading for children with CIs than for children with NH” suggesting that children who 
successfully build lexical and phonotactic repr esentations despite incomplete spectral 
resolution will bootstrap PA and ultimately achieve higher vocabulary and reading levels 
(98,99) . That is, converging syllable and lexical cues can be utilized to build partial 
phonotactic representations that are supported by non -spectral cues (i.e., temporal or 
spectrotempo ral) (100) . On the other hand, it is also plausible that some children cannot 
bootstrap the relative weaknesses in spectral resolutio n to PA (101)  and thus continue to 
display poor vocabular y and reading skills. We hypothesize that improving intracochlear 
spatial selectivity via IGCIP will lead to improvements in auditory function and speech 
recognition, which will facilitate bootstrapping of PA. IGCIP could provide a direct unique 
path to benefit PA —a plausible hypothesis that can be tested in this experimen tal 
design.  
There is a reliable relationship between speech recognition in noise and spectral 
resolution [e.g., (20,73,102,103) ] and emerging data supporting a relationship between 
PA and spectral resolution (19). However, in the presence of poor spectral resolution for 
children with CIs, we must examine the relative contributions of alternative paths taken 
from speech recogn ition to PA, speech, language, and reading. Figure 3  displays 
theorized models of IGCIP -mediated benefits of speech recognition and the subsequent 
effects on PA and receptive language. For 
example, it is plausible that there is an indirect 
path to PA media ted by a direct path through 
IGCIP -improved speech recognition. This can 
also be statistically tested within the context of a 
longitudinal double -blind, waitlist controlled RCT 
design, especially with measurements of 
potential mediators. A similar direct a nd indirect 
path can also be tested for IGCIP -gain scores in 
speech recognition and receptive language. 
Again, it is possible that IGCIP benefit directly 
improves receptive language and that this 
relationship is mediated via improvement in 
speech recogniti on resulting from IGCIP gain.  
Within the context of the current proposal, we have a unique opportunity to gain a 
better understanding of factors that predict speech, language, and reading outcomes in 
pediatric CI recipients. Specifically, the research act ivities proposed here  can compare 
the growth in spectral and temporal resolution, speech recognition, PA, speech, 
language, and reading following IGCIP within the context of a double blind, waitlist 
control led RCT. That is, hypothesized distal “benefits” r esulting from refinement of 
intracochlear spatial selectivity via IGCIP can be systematically studied with a waitlist 
control longitudinal RCT. Figure 3  includes examples of the basic design approach. A 
putative predictor, namely IGCIP gain scores for audi tory function, can be tested as a 
direct and indirect predictor of speech recognition and PA. The direct path is from IGCIP 
gain to the outcome which may be PA and/or receptive language. The strength of the 
longitudinal RCT design is that the indirect path  wherein speech recognition as a 
mediator of the relationship can also be tested. This design approach will also be 
employed to examine the direct and indirect relationships amongst speech recognition to 
receptive language, receptive language to expressive  language, and receptive language 
IGCIP path figure for Phonological Awareness (PA) 
 
 
IGCIP path figure for Receptive Language 
 
 
Figure 3. Direct and indirect (mediated) effects for IGCIP & 
speech recognition on PA and receptive language. 

Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
to reading comprehension in addition to speech recognition to PA and PA to reading 
comprehension.  
 
IMPACT  
 The impact of a personalized approach to CI programming  on auditory 
function, speech recognition, PA, language, sp eech, and reading will be examined as a 
step in programmatic research designed to optimize auditory, speech, language, PA and 
reading outcomes in children with CIs. Having access to personalized data regarding 
individualized anatomy, electrode location, an d electrode -to-modiolus distances will 
make this investigation the first of its kind in the space of outcomes -based research for 
pediatric CI recipients.  The use of a randomized wait -list control design will not only 
afford a prospective and longitudinal i nvestigation into the effects of IGCIP, but this 
design will enable us to  describe the expected growth trajectory for validated measures 
of speech recognition and psychophysical measures auditory perception for children with 
CIs over the course of a 2 -year period . Such data have never before been described 
with these measures  and thus this project offers high clinical relevance for audiologic 
management, test interpretation, and subsequent recommendations for pediatric CI 
recipients and their families  
 
5.        Literature Cited  
 
1.  Gifford H, Olund AP, Dejong M. Improving Speech Perception in Noise for Children with 
Cochlear Implants. 2012;632(2011):623 –32.  
2.  Gifford RH, Dorman MF, Skarzynski H, Lorens A, Po lak M, Driscoll CLW, et al. Cochlear 
implantation with hearing preservation yields significant benefit for speech recognition in 
complex listening environments. Ear Hear. 2013;34(4).  
3.  Uhler K, Warner -Czyz A, Gifford R, Group PW. Pediatric Minimum Speec h Test Battery. J 
Am Acad Audiol. 2017;28(3):232 –47.  
4.  Noble JH, Hedley -Williams AJ, Sunderhaus L, Dawant BM, Labadie RF, Camarata SM, et al. 
Initial Results With Image -guided Cochlear Implant Programming in Children. Otol 
Neurotol. 2016;37(2):e63 –9.  
5.  Nittrouer, S., Caldwell, A., Holloman C. Effectively predicting language and literacy in 
children with cochlear implants. Int Joural Pediatr Otorhinolaryngol. 2012;76(8):1148 –58.  
6.  Ruffin C V., Kronenberger WG, Colson BG, Henning SC, Pisoni DB. Long -term speech and 
language outcomes in prelingually deaf children, adolescents and young adults who 
received cochlear implants in childhood. Audiol Neurotol. 2013;18(5):289 –96.  
7.  Mayer, C., Trezek BJ. Literacy Outcomes in Deaf Students with Cochlear Impla nts: Current 
State of the Knowledge. J Deaf Stud Deaf Educ. 2017;23(1):1 –16.  
8.  Nittrouer S, Caldwell -Tarr A. Language and literacy skills in children with cochlear 
implants: past and present findings. In: Pediatric Cochlear Implantation. 2016. p. 177 –97.  
9.  Leigh, J. R., Dettman, S. J., Dowell RC. Evidence -based guidelines for recommending 
cochlear implantation for young children: Audiological criteria and optimizing age at 
implantation. Int J Audiol. 2016;55 Suppl 2:S9 –S18.  
10.  Tobey E a, Thal D, Ni parko JK, Eisenberg LS, Quittner AL, Wang N -Y. Influence of 
implantation age on school -age language performance in pediatric cochlear implant users. 
Int J Audiol [Internet]. 2013;52(4):219 –29. Available from: 
http://www.pubmedcentral.nih.gov/articlerender. fcgi?artid=3742378&tool=pmcentrez&re
ndertype=abstract  
11.  Niparko, J. K., Tobey, E. A., Thal, D. J., Eisenberg, L. S., Wang, N. Y., Quittner, A. L., 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
Fink, N. E. CdIT. Spoken Language Development in Children Following Cochlear 
Implantation. J Am Med Assoc.  2010;303(15):1498 –506.  
12.  Sharma A, Campbell J, Cardon G. Developmental and cross -modal plasticity in deafness: 
Evidence from the P1 and N1 event related potentials in cochlear implanted children. Int J 
Psychophysiol [Internet]. 2015;95(2):135 –44. Avai lable from: 
http://dx.doi.org/10.1016/j.ijpsycho.2014.04.007  
13.  Langereis, M., Vermeulen A. School performance and wellbeing of children with CI in 
different communicative -educational environments. Int Joural Pediatr Otorhinolaryngol. 
2015;79(6):834 –9.  
14.  Leigh JR, Dettman SJ, Dowell RC. Evidence -based guidelines for recommending cochlear 
implantation for young children: Audiological criteria and optimizing age at implantation. 
Int J Audiol [Internet]. 2016;55 Suppl 2(sup2):S9 –18. Available from: 
http://www.tandfonline.com/doi/full/10.3109/14992027.2016.1146415%5Cnhttp://www.n
cbi.nlm.nih.gov/pubmed/27142630  
15.  Niparko JK, Tobey EA, Thal DJ, Eisenberg LS, Wang N -Y, Quittner AL, et al. Spoken 
Language Development in Children Following Cochlear Implantation. J Am Med Assoc. 
2010;303(15):1498 –506.  
16.  Sharma A, Gilley PM, Dorman MF, Baldwin R. Deprivation -induced cortical reorganization 
in children with cochlear implants. Int J Audiol [Internet]. 2007;46(9):494 –9. Available 
from: http://www.tandfonline.com/doi/full/10.1080/14992020701524836  
17.  Dettman SJ, Dowell RC, Choo D, Arnott W, Abrahams Y, Davis A, et al. L ong-term 
Communication Outcomes for Children Receiving Cochlear Implants Younger Than 12 
Months. Otol Neurotol [Internet]. 2016;37(2):e82 –95. Available from: 
http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00129492 -
201602000 -00027  
18.  Newman, R., Chatterjee M. Toddlers’ recognition of noise -vocoded speech. J Acoust Soc 
Am. 2013;133(1):483 –494.  
19.  Nittrouer S, Lowenstein JH. Weighting of Acoustic Cues to a Manner Distinction by 
Children With and Without Hearing Loss. J Speech, Lang  Hear Res. 2015;24(2):1077 –92.  
20.  Gifford, R. H., Noble, J. H., Camarata, S. M., Sunderhaus, L. W., Dwyer, R. T., Dawant, B. 
M., Dietrich, M., Labadie RF. The relationship between spectral modulation detection and 
speech recognition: adult versus pediat ric cochlear implant recipients. Trends Hear. 
2018;22(1 –15).  
21.  Nittrouer S, Caldwell A, Holloman C. Measuring what matters: Effectively predicting 
language and literacy in children with cochlear implants. Int J Pediatr Otorhinolaryngol 
[Internet]. 2012 ;76(8):1148 –58. Available from: 
http://dx.doi.org/10.1016/j.ijporl.2012.04.024  
22.  Tinnemore, A. R., Zion, D. J., Kulkarni, A. M., Chatterjee M. Children’s Recognition of 
Emotional Prosody in Spectrally Degraded Speech Is Predicted by Their Age and Cognit ive 
Status. Ear Hear. 2018;2018 Jan 1.  
23.  Nittrouer S, Lowenstein JH, Holloman C. Early predictors of phonological and 
morphosyntactic skills in second graders with cochlear implants. Res Dev Disabil. 
2016;55:143 –60.  
24.  Noble JH, Gifford RH, Hedley -Williams AJ, Dawant BM, Labadie RF. Clinical evaluation of 
an image -guided cochlear implant programming strategy. Audiol Neurotol. 2014;19(6).  
25.  Noble JH, Gifford RH, Labadie RF, Dawant BM. Statistical shape model segmentation and 
frequency mapping of c ochlear implant stimulation targets in CT. Med Image Comput 
Comput Assist Interv. 2012;15.  
26.  Noble JH, Labadie RF, Gifford RH, Dawant BM. Image -Guidance enables new methods for 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
customizing cochlear implant stimulation strategies. IEEE Trans Neural Syst  Rehabil Eng. 
2013;21(5).  
27.  Nicholas JG, Geers AE. Will they catch up? The role of age at cochlear implantation in the 
spoken language development of children with severe to profound hearing loss. J Speech 
Lang Hear Res [Internet]. 2007;50(4):1048 –62. Available from: 
http://jslhr.pubs.asha.org/article.aspx?doi=10.1044/1092 -4388(2007/073)  
28.  Geers AE, Strube MJ, Tobey EA, Pisoni DB, Moog JS. Epilogue: Factors Contributing to 
Long-Term Outcomes of Cochlear Implantation in Early Childhood. Ear Hear [Inte rnet]. 
2011;32:84S –92S. Available from: 
http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00003446 -
201102001 -00010  
29.  Geers AE, Tobey EA, Moog J, Brenner C. Long -term outcomes of cochlear implantation in 
the preschool years: From ele mentary grades to high school. Int J Audiol. 
2008;47(S2):S21 -30.  
30.  Hayes H, Geers AE, Treiman R, Moog JS. Receptive vocabulary development in deaf 
children with cochlear implants: achievement in an intensive auditory -oral educational 
setting. Ear Hear.  2009;30(1):128 –35.  
31.  Holt RF, Beer J, Kronenberger WG, Pisoni DB, Lalonde K. Contribution of family 
environment to pediatric cochlear implant users’ speech and language outcomes: some 
preliminary findings. J Speech Lang Hear Res. 2012;55(3):848 –64.  
32.  Bouton, S., Serniclaes, W., Bertoncini, J., Colé P. Perception of speech features by French -
speaking children with cochlear implants. J Speech, Lang Hear Res. 2012;55(1):139 –53.  
33.  Peng SC, Tomblin JB, Cheung H, Lin YS, Wang LS. Perception and produ ction of mandarin 
tones in prelingually deaf children with cochlear implants. Ear Hear. 2004;25(3):251 –64.  
34.  Lee KY, van Hasselt CA, Chiu SN, Cheung DM. Cantonese tone perception ability of 
cochlear implant children in comparison with normal -hearing ch ildren. Int J Pediatr 
Otorhinolaryngol. 2002;63(2):137 –47.  
35.  Yeung HH, Werker JF. Learning words’ sounds before learning how words sound: 9 -
Month -olds use distinct objects as cues to categorize speech information. Cognition 
[Internet]. 2009;113(2):234 –43. Available from: 
http://dx.doi.org/10.1016/j.cognition.2009.08.010  
36.  Olszewski C, Gfeller K, Froman R, Stordahl J, Tomblin B. Familiar melody recognition by 
children and adults using cochlear implants and normal hearing children. Cochlear 
Implants In t. 2005;6(3):123 –40.  
37.  Jung KH, Won JH, Drennan WR, Jameyson E, Miyasaki G, Norton SJ, et al. Psychoacoustic 
performance and music and speech perception in prelingually deafened children with 
cochlear implants. Audiol Neurotol. 2012;17(3):189 –97.  
38.  Rosen S. Temporal information in speech: acoustic, auditory, and linguistic aspects. Philos 
Trans Biol Sci. 1992;336(1278):367 –73.  
39.  van Tasell DJ, Soli SD, Kirby VM, Widin GP. Speech waveform envelope cues for 
consonant recognition. J Acoust Soc Am. 1987;82(4):1152 –61.  
40.  van Tasell DJ, Greenfield DG, Logemann JJ, Nelson DA. Temporal cues for consonant 
recognition: training, talker generalization, and use in evaluation of cochlear implants. J 
Acoust Soc Am. 1992;92:1247 –57.  
41.  Shannon R V., Zeng  FG, Kamath V, Wygonski J, Ekelid M. Speech Recognition with 
Primarily Temporal Cues. Science (80 - ). 1995;270:303 –4.  
42.  Hong, R. S., Rubinstein JT. High -rate conditioning pulse trains in cochlear implants: 
dynamic range measures with sinusoidal stimuli. J Acoust Soc Am. 2003;114:3327 –3342.  
43.  Litvak, L. M., Smith, Z. M., Delgutte, B., Eddington DK. Desynchronization of e lectrically 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
evoked auditory nerve activity by highfrequency pulse trains of long duration. J Acoust 
Soc Am. 2003;114:2066 –78.  
44.  Loizou, P. C., Poroy O. Minimum spectral contrast needed for vowel identification by 
normal hearing and cochlear implant lis teners. J Acoust Soc Am. 2001;110:1619 –27.  
45.  Drennan WR, Won JH, Nie K, Jameyson E, Rubinstein JT. Sensitivity of psychophysical 
measures to signal processor modifications in cochlear implant users. Hear Res. 
2010;262(2 –2):1–8.  
46.  Holder, J. T., Kes sler, D., Gifford, R. H., Noble, J. H., Labadie RF. Prevalence of 
extracochlear electrodes: CT scans, cochlear implant maps, and operative reports. Otol 
Neurotol. 2018;epub ahead.  
47.  Bierer JA, Litvak L. Channel Interaction Through Cochlear Implant Prog ramming May 
Improve Speech Perception: Current Focusing and Channel Deactivation. Trends Hear. 
2016;20:1 –12.  
48.  Vickers D, Degun A, Canas A, Stainsby T, Vanpoucke F. Deactivating Cochlear Implant 
Electrodes Based on Pitch Information for Users of the AC E Strategy. Adv Exp Med Biol. 
2016;894:115 –23.  
49.  Zhou N. Deactivating stimulation sites based on low -rate thresholds improves spectral 
ripple and speech reception thresholds in cochlear implant users. J Acoust Soc Am. 
2017;141(3):EL243.  
50.  Debruyne JA, Francart T, Janssen AM, Douma K, Brokx JP. Fitting prelingually deafened 
adult cochlear implant users based on electrode discrimination performance. Int J Audiol. 
2017;56(3):174 –85.  
51.  Mens LH, Berenstein CK. Speech perception with mono - and quadrup olar electrode 
configurations: a crossover study. Otol Neurotol. 2005;26(5):957 –64.  
52.  Srinivasan AG, Landsberger DM, Shannon R V. Current Focusing Sharpens Local Peaks of 
Excitation in Cochlear Implant Stimulation. Hear Res [Internet]. 2010;270(1 –2):89 –100. 
Available from: http://tia.sagepub.com/cgi/doi/10.1177/2331216516653389  
53.  Frijns JH, Dekker DM, Briaire JJ. Neural excitation patterns induced by phased -array 
stimulation in the implanted human cochlea. Acta Otolaryngol. 2011;131(4):362 –70.  
54.  Bierer JA, Faulkner KF, Tremblay KL. Identifying cochlear implant channels with poor 
electrode -neuron interface: electrically -evoked auditory brainstem responses measured 
with the partial tripolar configuration. Ear Hear. 2011;32(4):436 –44.  
55.  Litvak LM , Spahr AJ, Emadi G. Loudness growth observed under partially tripolar 
stimulation: model and data from cochlear implant listeners. J Acoust Soc Am [Internet]. 
2007;122(2):967 –81. Available from: http://www.ncbi.nlm.nih.gov/pubmed/17672645  
56.  Padilla M, Landsberger DM. Reduction in spread of excitation from current focusing at 
multiple cochlear locations in cochlear implant users. Hear Res. 2016;333:98 –107.  
57.  Landsberger DM, Srinivasan AG. Virtual channel discrimination is improved by current 
focusing in cochlear implant recipients. Hear Res. 2009;254(1 –2):34 –41.  
58.  Arenberg JG, Parkinson WS, Litvak L, Chen C, Kreft HA, Oxenham AJ. A Dynamically 
Focusing Coc hlear Implant Strategy Can Improve Vowel Identification in Noise. Ear Hear. 
2018;2018 March:epub ahead of print.  
59.  Won JH, Drennan WR, Nie K, Jameyson EM, Rubinstein JT. Acoustic temporal modulation 
detection and speech perception in cochlear implant l isteners. J Acoust Soc Am [Internet]. 
2011;130(1):376 –88. Available from: http://asa.scitation.org/doi/10.1121/1.3592521  
60.  Saoji AA, Litvak L, Spahr AJ, Eddins DA. Spectral modulation detection and vowel and 
consonant identifications in cochlear implant  listeners. J Acoust Soc Am [Internet]. 
2009;126(3):955 –8. Available from: isi:000269833600009  
61.  Litvak LM, Spahr AJ, Saoji AA, Fridman GY. Relationship between perception of spectral 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
ripple and speech recognition in cochlear implant and vocoder listene rs. J Acoust Soc Am. 
2007;122(2):982 –91.  
62.  Drennan WR, Won JH, Nie K, Jameyson E, Rubinstein JT. Sensitivity of psychophysical 
measures to signal processor modifications in cochlear implant users. Hear Res. 
2010;262(1 –2):1–8.  
63.  Zhang T, Spahr AJ, D orman MF, Saoji A. Relationship Between Auditory Function of 
Nonimplanted Ears and Bimodal Benefit. Ear Hear [Internet]. 2013;34(2):133 –41. 
Available from: http://www.ncbi.nlm.nih.gov/pubmed/23075632  
64.  Gifford RH, Hedley -Williams A, Spahr AJ. Clinical a ssessment of spectral modulation 
detection for adult cochlear implant recipients: A non -language based measure of 
performance outcomes. Int J Audiol. 2014;53(3).  
65.  Altmann CF, Gaese BH. Representation of frequency -modulated sounds in the human 
brain. H ear Res [Internet]. 2014;307:74 –85. Available from: 
http://dx.doi.org/10.1016/j.heares.2013.07.018  
66.  Drennan WR, Anderson ES, Won JH, Rubinstein JT. Validation of a clinical assessment of 
spectral -ripple resolution for cochlear implant users. Ear Hear [ Internet]. 2014;35(3):e92 -
8. Available from: http://www.ncbi.nlm.nih.gov/pubmed/24552679  
67.  Henry BA, Turner CW, Behrens A. Spectral peak resolution and speech recognition in 
quiet: normal hearing, hearing impaired, and cochlear implant listeners. J Acou st Soc Am 
[Internet]. 2005;118(2):1111 –21. Available from: 
http://scitation.aip.org/content/asa/journal/jasa/118/2/10.1121/1.1944567  
68.  Henry BA, Turner CW. The resolution of complex spectral patterns by cochlear implant 
and normal -hearing listeners. J A coust Soc Am. 2003;113(5):2861 –2873.  
69.  Won JH, Drennan WR, Rubinstein JT. Spectral -ripple resolution correlates with speech 
reception in noise in cochlear implant users. JARO - J Assoc Res Otolaryngol. 
2007;8(3):384 –92.  
70.  Drennan WR, Won JH, Timme AO, Rubinstein JT. Non -linguistic outcome m easures in 
adult cochlear implant users over the first year of implantation. Vol. 37. 2016. 354 -364 p.  
71.  Labadie RF, Noble H, Hedley -Williams J, Sunderhaus ZW, Dawant M, Gifford ZH. Results 
of Postoperative, CT -based, Electrode Deactivation on Hearing in Prelingually Deafened 
Adult Cochlear Implant Recipients. Otol Neurotol. 2016;37:137 –45.  
72.  Landsberger DM, Padilla M, Martinez AS, Eisenberg LS. Spectral -Temporal Modulated 
Ripple Discrimination by Children With Cochlear Implants. Ear Hear. 2017;epub  ahead.  
73.  Horn DL, Dudley DJ, Dedhia K, Nie K, Drennan WR, Won JH, et al. Effects of age and 
hearing mechanism on spectral resolution in normal hearing and cochlear -implanted 
listeners. J Acoust Soc Am. 2017;613 –623.  
74.  DiNino M, Arenberg JG. Age -Related Performance on Vowel Identification and the 
Spectral -temporally Modulated Ripple Test in Children With Normal Hearing and With 
Cochlear Implants. Trends Hear. 2018;22:1 –20.  
75.  Nittrouer S, Caldwell -Tarr A, Lowenstein JH. Working memory in children  with cochlear 
implants: problems are in storage, not processing. Int J Pediatr Otorhinolaryngol. 
2013;77:1886 –98.  
76.  Nittrouer S, Caldwell -Tarr A, Low KE, Lowenstein JH. Verbal Working Memory in Children 
With Cochlear Implants. J Speech, Lang Hear Res.  2017;60:3342 –64.  
77.  Camarata, S., Werfel, K., Davis, T., Hornsby, B. & Bess F. Language Abilities, Phonological 
Awareness, Reading Skills, and Subjective Fatigue in School -Age Children with Mild -to-
Moderate Hearing Loss. Except Child. 2018;epub ahead.  
78.  Pisoni DB, Kronenberger WG, Roman AS, Geers AE. Measures of digit span and verbal 
rehearsal speed in deaf children after more than 10 years of cochlear implantation. Ear 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
Hear. 2011;32:60S –74S.  
79.  McCreery RW, Spratford M, Kirby B, Brennan M. Indiv idual differences in language and 
working memory affect children’s speech recognition in noise. Int J Audiol. 2017;56:306 –
15.  
80.  Ingvalson EM, Young NM, Wong PC. Auditory -cognitive training improves language 
performance in prelingually deafened cochlear  implant recipients. Int J Pediatr 
Otorhinolaryngol. 2014;78(10):1624 –31.  
81.  Harris MS, Pisoni DB, Kronenberger WG, Gao S, Caffrey HM, Miyamoto RT. Developmental 
trajectories of forward and backward digit spans in deaf children with cochlear implants. 
Cochlear Implants Int. 2011;12 Suppl 1:S84 –S88.  
82.  Cooper R, Rosenstein J. Language acquisition of deaf children. Volta Rev. 1966;68(1):58 –
67.  
83.  Fry DB, Whetnall E. The auditory approach in the training of deaf children. Lancet. 
1954;263(6812):583 –7.  
84.  Hampleman RS. Comparison of listening and reading comprehension ability of fourth and 
sixth grade pupils. Elem English. 1958;35(1):49 –53.  
85.  Harris, M., Terlektsi, E., & Kyle FE. Literacy outcomes for primary school children who are 
deaf and hard  of hearing: A cohort comparison study. J Speech, Lang Hear Res. 
2017;60(3):701 –11.  
86.  Meinzen -Derr, J., Sheldon, R., Grether, S., Altaye, M., Smith, L., Choo, D. I., Wiley S. 
Underperformance in Young Children Who Are Deaf or Hard -of-Hearing: Are the 
Expectations Too Low? J Dev Behav Pediatr. 2018;39(2):116 –25.  
87.  Johnson C, Goswami U. Phonological awareness, vocabulary and reading in deaf children 
with cochlear implants. J Speech Lang Hear Res. 2010;53:237 –61.  
88.  Nittrouer S, Sansom E, Low K, Ric e C, Caldwell -Tarr A. Language structures used by 
kindergartners with cochlear implants: relationship to phonological awareness, lexical 
knowledge and hearing loss. Ear Hear. 2014;35(5):506 –18.  
89.  Deeb D, Gao X, Jiang H, Arbab AS, Dulchavsky SA, Gautam SC. Growth inhibitory and 
apoptosis -inducing effects of xanthohumol, a prenylated chalone present in hops, in 
human prostate cancer cells. Anticancer Res. 2010;30(9):3333 –9.  
90.  Bailey, P. J., Snowling MJ. Auditory processing and the development of langu age and 
literacy. Br Med Bull. 2002;63:135 –46.  
91.  Nittrouer, S., Lowenstein JH. Learning to perceptually organize speech signals in native 
fashion. J Acoust Soc Am. 2010;127(3):1624 –35.  
92.  White -Schwoch, T., Carr, K. W., Thompson, E. C., Anderson, S. , Nicol, T., Bradlow, A. R., 
Zecker, S.G. & Kraus N. Auditory processing in noise: A preschool biomarker for literacy. 
PLoS Biol. 2015;13(7):e1002196.  
93.  Carroll, J. M., & Snowling MJ. The effects of global similarity between stimuli on children’s 
judgm ents of rime and alliteration. Appl Psycholinguist. 2001;22:327 –42.  
94.  Metsala, J. L., & Walley AC. Spoken vocabulary growth and the segmental restructuring of 
lexical representations: precursors to phonemic awareness and early reading ability. In: 
Ehri JLM& LC, editor. Word recognition in beginning literacy. Hillsdale, NJ: Erlbaum; 1998. 
p. 89–120.  
95.  Venturaa, P., Kolinsky, R., Fernandesa, S., Queridoa, L., Morais J. Lexical restructuring in 
the absence of literacy. Cognition. 2007;105(2):334 –61.  
96.  Carroll, J. M., Snowling, M. J., Hulme, C., Stevenson J. The development of phonological 
awareness in preschool children. Dev Psychol. 2003;39:913 –23.  
97.  Storkel HL. Learning new words: Phonotactic probability in language development. J 
Speech, Lan g Hear Res. 2001;44(6):1321 –37.  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
98.  Nittrouer, S., Caldwell, A., Lowenstein, J. H., Tarr, E., Holloman C. Emergent literacy in 
kindergartners with cochlear implants. Ear Hear. 2012;33(6):683 –97.  
99.  Klein, K. E., Walker, E. A., Kirby, B., & McCreery RW . Vocabulary Facilitates Speech 
Perception in Children With Hearing Aids. J Speech, Lang Hear Res. 2017;60(8):2281 –96.  
100.  Nittrouer, S., Studdert -Kennedy, M., & McGowan RS. The emergence of phonetic 
segments: Evidence from the spectral structure of fricative -vowel syllables spoken by 
children and adults. J Speech, Lang Hear Res. 1989;32(1):120 –32.  
101.  Han MK, Storkel HL, L ee J, Yoshinaga -Itano C. The influence of word characteristics on 
the vocabulary of children with cochlear implants. J Deaf Stud Deaf Educ. 
2015;20(3):242 –51.  
102.  Baer T, Moore BCJ, Gatehouse S. Spectral contrast enhancement of speech in noise for 
listeners with sensorineural hearing impairment: effects on intelligibility, quality, and 
response times. J Rehabil Res Dev. 1993;30(1):49 –72.  
103.  Nittrouer, S., Tarr, E., Wucinich, T., Moberly, A. C., Lowenstein JH. Measuring the effects 
of spectral smearin g and enhancement on speech recognition in noise for adults and 
children. J Acoust Soc Am [Internet]. 2015;137(4):2004 –14. Available from: 
http://asa.scitation.org/doi/10.1121/1.4916203  
104.  Wanna GB, Balachandran R, Majdani O, Mitchell J, Labadie RF. Per cutaneous access to 
the petrous apex in vitro using customized micro -stereotactic frames based on image -
guided surgical technology. Acta Otolaryngol. 2009;25:1 –6.  
105.  Schuman TA, Noble JH, Wright CG, Wanna GB, Dawant BM, Labadie RF. Anatomic 
verificatio n of a novel method for precise intrascalar localization of cochlear implant 
electrodes in adult temporal bones using clinically available computed tomography. 
Laryngoscope. 2010;120(11):2277 –83.  
106.  Peterson GE, Lehiste I. Revised CNC lists for auditor y tests. J Speech Hear Disord. 
1962;27:62 –70.  
107.  Spahr AJ, Dorman MF, Litvak LM, Cook SJ, Loiselle LM, Dejong MD, et al. Development 
and validation of the pediatric AzBio sentence lists. Ear Hear. 2014;35(4).  
108.  Etymotic R. BKB -SIN TEST. 2005.  
109.  Holder JT, Sheffield SW, Gifford RH. Speech understanding in children with normal 
hearing: Sound field normative data for babybio, BKB -SIN, and QuickSIN. Otol Neurotol. 
2016;37(2).  
110.  Fu Q-J. Temporal processing and speech recognition in cochlear im plant users. 
Neuroreport [Internet]. 2002;13(13):1635 –9. Available from: 
http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2704892&tool=pmcentrez&re
ndertype=abstract  
111.  Carrow -Woolfolk E. Test of Auditory Comprehension of Language (TACL3). Austi n, Texas; 
1999.  
112.  Goldman R, Fristoe M. Goldman -Fristoe Test of Articulation, 2nd edition (GFTA -2). 
Bloomington, MN; 2000.  
113.  Casserly ED, Pisoni DB. Nonword repetition as a predictor of long -term speech and 
language skills in children with cochle ar implants. Otol Neurotol. 2013;34(3):460 –70.  
114.  Nittrouer, S., Caldwell -Tarr, A., Sansom, E., Twersky, J., & Lowenstein JH. Nonword 
repetition in children with cochlear implants: A potential clinical marker of poor language 
acquisition. Am J speech -language Pathol. 2014;23(4):679 –95.  
115.  Wiseman, K. B., Warner -Czyz A. Inconsistent device use in pediatric cochlear implant 
users: Prevalence and risk factors. Cochlear Implants Int. 2018;19:131 –41.  
116.  Busch, T., Vanpoucke, F., van Wieringen A. Audi tory environment across the life span of 
cochlear implant users: insights from data logging. J Speech, Lang Hear Res. 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
2017;60:1362 –77.  
117.  Moog JS, Geers AE. Early educational placement and later language outcomes for children 
with cochlear implants. Ot ol Neurotol. 2010;31(8):1315 –9.  
118.  Tobey EA, Geers AE, Brenner C, Altuna D, Gabbert G. Factors Associated with 
Development of Speech Production Skills in Children Implanted by Age Five. Ear Hear. 
2003;24:36S –45S.  
119.  Davidson LS, Geers AE, Brenner C . Cochlear implant characteristics and speech perception 
skills of adolescents with long -term device use. Otol Neurotol. 2010;31(8):1310 –4.  
120.  Skinner MW, Holden LK, Holden TA, Demorest ME. Comparison of Two Methods for 
Selecting Minimum Stimulation Le vels Used in Programming the Nucleus 22 Cochlear 
Implant. J Speech, Lang Hear Res. 1999;42:814 –28.  
121.  Walkowiak A, Lorens A, Kostek B, Skarzynski H, Polak M. ESRT, ART, and MCL 
Correlations in Experienced Paediatric Cochlear Implant Users. Cochlear Imp lants Int 
[Internet]. 2010;11(sup1):482 –4. Available from: 
http://www.tandfonline.com/doi/full/10.1179/146701010X12671177204741  
122.  Wolfe J, Gilbert M, Schafer E, Litvak LM, Spahr AJ, Saoji A, et al. Optimizations for the 
Electrically -Evoked Stapedial Re flex Threshold Measurement in Cochlear Implant 
Recipients. Ear Hear. 2016;1 –7.  
123.  de Andrade KCL, Muniz LF, Menezes PL, Neto SDSC, Carnaúba ATL, Leal MC. The Value of 
Electrically Evoked Stapedius Reflex in Determining the Maximum Comfort Level of a 
Cochlear Implant. J Am Acad Audiol. 2018;29(4):292 –9.  
124.  Scollie S, Seewald R, Cornelisse L, Moodie S, Bagatto M, Laurnagaray D, et al. The 
Desired Sensatio n Level multistage input/output algorithm. Trends Amplif. 2005;9(4):159 –
97.  
125.  Friesen LM, Shannon R V., Baskent D, Wang X. Speech recognition in noise as a function 
of the number of spectral channels: comparison of acoustic hearing and cochlear 
implan ts. J Acoust Soc Am [Internet]. 2001;110(2):1150 –63. Available from: 
http://link.aip.org/link/JASMAN/v110/i2/p1150/s1&Agg=doi  
126.  Shannon R V., Cruz RJ, Galvin JJ. Effect of stimulation rate on cochlear implant users’ 
phoneme, word and sentence recogniti on in quiet and in noise. Audiol Neurotol. 
2011;16(2):113 –23.  
127.  Noble, J. H., Gifford, R. H., Hedley -Williams, A. J., Dawant, B. M., Labadie RF. Clinical 
evaluation of an imageguided cochlear implant programming strategy. Audiol Neurootol. 
2014;19(6): 400–11.  
128.  Saoji AA, Eddins DA. Spectral modulation masking patterns reveal tuning to spectral 
envelope frequency. J Acoust Soc Am [Internet]. 2007;122(2):1004 –13. Available from: 
http://www.ncbi.nlm.nih.gov/pubmed/17672648  
129.  Viemeister NF. Tempora l modulation transfer functions based upon modulation 
thresholds. J Acoust Soc Am. 1979;66(5):1364 –80.  
130.  Houtgast T, Steeneken HJM. A review of the MTF concept in room acoustics and its use 
for estimating speech intelligibility in auditoria. J Acoust Soc Am [Internet]. 
1985;77(3):1069 –77. Available from: http://asa.scitation.org/doi/10.1121/1.392224  
131.  Bernstein, J. G., Danielsson, H., Hällgren, M., Stenfelt, S., Rönnberg, J. LT. 
Spectrotemporal Modulation Sensitivity as a Predictor of Speech -Recept ion Performance in 
Noise With Hearing Aids. Trends Hear. 2016;20:1 –20.  
132.  Levitt H. Transformed up -down methods in psychoacoustics. J Acoust Soc Am. 
1971;49(2):467 –77.  
133.  Metsala, J. L., Stavrinos, D., & Walley AC. Children’s spoken word recognitio n and 
contributions to phonological awareness and nonword repetition: A 1 -year follow -up. Appl 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
Psycholinguist. 2009;30(1):101 –21.  
134.  Nilsson M, Soli SD, Sullivan JA. Development of the Hearing in Noise Test for the 
measurement of speech reception thresholds in quiet and in noise. J Acoust Soc Am. 
1994;95(2):1085 –99.  
135.  Lebo CP, Smith MFW, Mosher ER, Jelonek SJ, Schwind DR, Decker KE , et al. Restaurant 
Noise, Hearing Loss, and Hearing Aids. West J Med. 1994;161(1):45 –9.  
136.  Farber GS, Wang LM. Analyses of crowd -sourced sound levels of restaurants and bars in 
New York City. Proc Mtgs Acoust. 2017;31:1 –15.  
137.  Crukley J, Scollie S , Parsa V. An Exploration of Non -Quiet Listening at School. J Educ 
Audiol. 2011;17:23 –35.  
138.  Pearsons KS, Bennett RL, Fidell S. Speech levels in various noise environments. 
Washington, DC; 1977.  
139.  Lee, Y., Yim, D., & Sim H. Phonological processing  skills and its relevance to receptive 
vocabulary development in children with early cochlear implantation. Int Joural Pediatr 
Otorhinolaryngol. 2012;76(12):1755 –60.  
140.  Thornton, A. R., Raffin MJ. Speech -discrimination scores modeled as a binomial vari able. J 
Speech Hear Res. 1978;21(3):507 –18.  
141.  Meinzen -Derr J, Wiley S, Creighton J, Choo D. Auditory Skills Checklist: clinical tool for 
monitoring functional auditory skill development in young children with cochlear implants. 
Ann Otol Rhinol Laryngo l. 2007;116(11):812 –8.  
142.  Ching TYC, Hill M. The Parents’ Evaluation of Aural/Oral Performance of Children (PEACH) 
Scale: Normative Data. J Am Acad Audiol. 2007;18:220 –35.  
144.  Brownell R. Receptive One -Word Picture Vocabulary Tests, Fourth Edition ( ROWPVT -4). 
Bloomington, MN; 2010.  
145.  Dunn LM, Dunn DM. Peabody Picture Vocabulary Test, Fourth Edition (PPVTTM-4). 
Bloomington, MN; 2007.  
146.  Carrow -Woolfolk E. TACL -4: Test for Auditory Comprehension of Language –Fourth 
Edition. Austin, Texas; 2014.   
147.  Semel E, Wiig EH, Secord WA. Clinical Evaluation of Language Fundamentals® - Fourth 
Edition (CELF® - 4). Bloomington, MN; 2003.  
148.  Brownell R. Expressive One -Word Picture Vocabulary Tests, Fourth Edition (EOWPVT -4). 
Bloomington, MN; 2010.  
149.  Dawson J, Stout C. SPELT -3: The Structured Photographic Expressive Language Test -
Third Edition. Greenville, SC; 2003.  
150.  Goldman R, Fristoe M. Goldman -Fristoe Test of Articulation 3: (GFTA -3). Bloomington, 
MN; 2015.  
151.  Glasgow C, Cowley J. Renfrew Bus Story test - North American Edition. Centreville, DE;  
152.  Berisha V, Liss J, Wisler A. Aural Analytics. Tempe, AZ: Aural Analytics, LLC; 2015.  
153.  Jiao Y, Berisha V, Liss J. Interpretable phonological features for cli nical applications. In: 
IEEE International Conference on Acoustics, Speech, and Signal Processing. New Orleans, 
LA; 2017.  
154.  Roid GH, Miller LJ. Leiter International Performance Scale, Third Edition. 2013.  
155.  Schrank FA, McGrew KS, Mather N. Woodco ck-Johnson IV. Riverside, IL: Rolling 
Meadows; 2014.  
156.  Melby -Lervag M, Hulme C. Serial and free recall in children can be improved by training: 
evidence for the importance of phonological and semantic representations in immediate 
memory tasks. Psychol  Sci. 2010;21:1694 –700.  
157.  Nittrouer S, Miller ME. The development of phonemic coding strategies for serial recall. 
Appl Psycholinguist. 1999;20:563 –88.  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
158.  Gillon GT. Phonological Awareness. 2nd editio. New York, NY: Guilford Press; 2017.  
159.  Wagner R, Torgesen J, Rashotte C, Pearson NA. Comprehensive Test of Phonological 
Processing, Second Edition (CTOPP -2). Bloomington, MN; 2013.  
160.  Martin NA, Brownell R. Test of Auditory Processing Skills, third edition (TAPS -3). Austin, 
Texas; 2005.  
161.  Ching TY, Cupples L. Phonological Awareness at 5 years of age in Children who use 
Hearing Aids or Cochlear Implants. Perspect Hear Hear Disord Child. 2015;25(2):48 –59.  
162.  Fuchs D, Hendricks E, Walsh ME, Fuchs LS, Gilbert JK, Tracy WZ, et al. Evaluati ng a 
Multidimensional Reading Comprehension Program and Reconsidering the Lowly 
Reputation of Tests of Near ‐Transfer. Learn Disabil Res Pract. 2018;33(1):11 –23.  
163.  Woodcock RW. Woodcock Reading Mastery Tests, Third Edition (WRMTTM-III). 
Bloomington, MN; 2011.  
164.  Bryant BR, Wiederholt JL. GORT -5: Gray Oral Reading Tests−Fifth Edition. Bloomington, 
MN; 2011.  
 
 
3.0 Inclusion/Exclusion Criteria  
 
We anticipate enrollment of 72 study participants to achieve our target goal of 60 comp leted 
participants (30 in each group).   
 
The following inclusion and  exclusi on criteria  will be used:  
 
Inclusion  Criteria:  
• children aged 4.5 to 12 years of age  
• prelingual onset of deafness  
• at least one CI and bilateral  moderate to profound sensorineural hearing loss  
o for children with a single CI, audiometric thresholds in the non -CI ear 
must be consistent with at least a moderate to profound sensorineural 
hearing loss  
• cochlear implantation prior to 4 years of age  
• nonverbal cognitive abilities within the typical range  
• no confounding diagnosis such as autism spectrum disorder, neurological 
disorder, or general cognitive impairment  
• pre-operative  CT scan of head performed as standard  of care preoperative CI 
work-up 
• post-operative CT scan —obtained either before enrollment (per VUMC CI 
program standard of care) or after informed consent, if implanted 
elsewhere. Note that if an outside implanted participant is recruited for 
study participation, Co -I Dr. Labadie has an a ctive IRB approved study —
which will be linked to this study’s IRB application —allowing for Xoran CT 
scanning of children aged 4 years and older. Four years of age is the 
youngest age for which this can be reliably completed given the need to sit 
completely  still for ~15 seconds.  
 
Exclusion  Criteria:  
• severe anatomical  abnormality(s)  of the temporal  bone (e.g., common cavity, 
cochlear ossification)  
• onset of moderate -to-profound sensorineural hearing loss after 2 years of 
age 
• nonverbal intelligence standard score < 85  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
 
 
4.0 Enrollment/Randomization  
 
 
Patients  will be recruit ed from the CI program at  Vanderbilt University  Medical  Center, one of 
the largest programs in the United States, with an average of 250 CI recipients annually (65% 
adult) and over 3000 recipients since inception in 1996.  Over the duration of the study, We 
anticipate enrollment of 72 study participants to achieve our target sampl e size of 60 completed 
participants (30 in each group).  Each year we implant approximately 60 to 80 pediatric CI 
patients. An analysis of all pediatric CI recipients implanted at Vanderbilt University Medical 
Center from January 2011 through December 2017 revealed that we have 251 pediatric CI 
recipients aged 6 to 12 years of age with prelingual onset of bilateral moderate to profound 
sensorineural hearing loss, who were younger than 3 years of age at implantation. However, 
there are over 220 additional pro spective participants already being followed by our center who 
will reach the age -inclusion criteria over the course of the project. Informed  consent and assent 
will take place as per our institution’s IRB policies and be obtained  by the PIs, co-Is, and/or  
other appropriately trained member  of the research  team using an IRB-approv ed consent  form.  
 
Study retention will be promoted by providing the parents and children with detailed 
information regarding their performance on various tasks of auditory processing, speech 
recognition, speech production, language, and literacy. Following each study visit, we will 
compile a report of each child’s performance to be mailed to the child’s home address on file. 
Study participation will provide value -added information regarding a variety of auditory, speech, 
language, and literacy tasks that are not typically included in clinical appointments.  
 
A list of pediatric patients who already have a CI will be obtained  from our VUMC  Cochlear 
Implant Program database . Only KSP with routine access to these patients' medical records will 
access their PHI to determine eligibility and contact information. A letter  or email  describing the 
study and asking for interest in participation will  then be sent and/or a phone call will be made 
to each individual identified ( the telephone script for the phone call will be the same as the 
Prospective Study Particip ant letter which is attached ). Another possibility for enrolling 
prospective participant s is when these patients are seen in clinic for routine follow -up, the 
surgeon  and/or audiologist can pass along the information about this study either verbally or by 
pointing the patient to a recruitment document . If a VUMC  patient expressed interest, th e 
clinician can page one of the KSP and s tudy participation  will be discussed with the potential 
participant.  All researchers and/or research assistants who are trained in proper test 
administration may access EPIC (eStar)  for the purpose s of verifying pa rticipant eligibility prior 
to initializing contact .  
 
In addition to standard re cruitment methods as described here, this study  is registered with 
clinicaltrials.gov as it is a randomized controlled trial (RCT).  
 
5.0 Study Procedures  
 
First, informed consent will be obtained for all participants. Interested participants will be 
provided a written form containing the elements of informed consent: description of the 
experiment, time necessary to complete the experiment, remuneration, a statement  that the 
experiment will not enhance or  harm the health of the participant, a statement that the 
participant may withdraw at any time without prejudice without affecting their medical care at 
Vanderbilt University Medical Center, a statement that the iden tity of the subject will be  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
confidential, and an indication of the phone and address of the IRB official to contact if there are 
questions.  
 
The experimenter will then ask open ended probing questions to ensure that the participant 
understands the purpose of the study and the study activities such as, "Can you provide a brief 
explanation of what you will be doing in this experiment?"  
 
We will be looking for dissenting behaviors from the child such as hiding, crying, or not making 
eye contact.  
 
Study proced ures:  
 The proposed study is a relatively straight -forward, double blind, waitlist controlled RCT. 
The total initial sample  (n=72) will be randomly assigned to either immediate IGCIP intervention 
(n=36) or a deferred waitlist condition (n=36). Both groups will be monitored for 24 months 
(Table 3 ), with testing at time 1 (baseline), time 2 (2 months), time 3 (6 months), and tim e 4 
(12 months). After 12 months, the 
deferred treatment group will 
receive the IGCIP intervention and 
testing will then continue for both 
groups  at time 5 (14 months), 
time 6 (18 months), and time 7 
(24 months). At completion, we 
will have 12 months of da ta on 
untreated growth, 12 months of 
treated growth in the deferred group, and 24 months of growth in the immediate IGCIP group. 
Note that “growth” can be positive, negative or neutral within in this design. Importantly, a 
between -group comparison of treat ed and untreated growth will be completed for data collected 
at 12 months. The study also permits comparison of growth at 24 months between groups 
(immediate vs. deferred treatment), which provides strong testing of IGCIP intervention effects.  
 We will en sure optimization of CI mapping including CI-aided thresholds in the range of 
20 to 25 dB HL from 250 through 6000 Hz  (119,120)  as well as verification of upper stimulation 
levels via electrically evoked stapedial reflex thresholds (ESRTs)  (121–123). For unilateral CI 
users with a hearing aid in the non -CI ear, we will verify hearing aid settings vi a real -ear 
measures  using the desired sensation level v5 prescriptive fitting formula  (124) . If clinical CI 
mapping was not completed per this protocol, we will program the child’s CI and wait at least 2 
months prior to completing a baseline assessment. If mid dle ear status does not allow ESRT 
measurements (e.g., effusion and/or PE tubes), upper stimulation levels will be obtained 
behaviorally, per clinical protocol. We will also complete thorough listening checks and test 
external equipment for signs of malfun ction at every study visit.  
 
Procedures  
 IGCIP. IGCIP provides an automated  electrode position analysis accounting for non -rigid 
variations in individualized cochlear anatomy requiring pre - and post -implant CT for all study 
participants. Pre - and post -operative CT scans are considered standard of care treatme nt for all 
CI recipients at Vanderbilt given the electrode information provided by the image -guided analysis. 
We will define the electrode -to-modiolus interface by calculating distance -versus -frequency 
curves and then implementing a minimum error neural ne twork to determine which electrodes for 
which their local minima (shortest electrode to modiolar distance) would be completely 
encompassed by adjacent electrodes. The goal is to maximize the number of active electrodes 
[>8 electrodes (125,126) ] but also eliminate electrodes providing “redundant” electrical 
TABLE 3 Baseline 1 
mo** 2 
mo 6 
mo 12 
mo 13 
mo** 14 
mo 18 
mo 24 
mo 
Spectral, temporal, & 
spectrotemporal res X  X X X  X X X 
Speech rec X X X X X X X X X 
Subjective 
questionnaires X  X X X  X X X 
Speech production X  X X X  X X X 
Working memory, 
language, non-verbal 
cognition, PA, & literacy X    X    X 
**SmartPhone app at home 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
stimulation (i.e. channel interaction) or extracochlear electrodes. With IGCIP deac tivation, we 
hypothesize a reduction in channel interaction which should increase spatial selectivity, and 
hence spectrotemporal resolution and speech recognition in noise. For bilateral CI users, IGCIP 
will be implemented for just 1 CI, targeting the poor er performing ear or the 2nd CI ear in the 
absence of interaural performance differences. This has been the IGCIP approach for all previous 
studies (4,71,127)  and offers built -in control of the non -IGCIP ear as well as the bilateral CI 
condition (also see data presented in Preliminary Studies ). 
 Spectral  and Temporal Resolution. All tasks of spectral  and temporal resolution will 
utilize a 3-interval, 2 -alternative forced -choice procedure with broadband noise (125 to 8000 Hz) 
presented at 65 dB SPL in the sound field . For spectral resolution , the participant w ill be asked 
to discriminate between noises with a flat spectrum and those with spectral modulation at rates 
of 0.5 and 1.0 cyc/oct —these rates have been shown to be significantly correlated with various 
measures of speech recognition (60,61,128) . Temporal resolution  will be assessed using 
amplitude modulation detection tasks in which the listener is asked to discriminate between 
noises with a flat temporal envel ope and those with sinusoidal amplitude modulation at rates of 
4, 32, and 128 Hz.  These rates were chosen to define the plateau of the temporal modulation 
transfer function (4 -32 Hz) as well as the sloping portion of the function (128 Hz) [e.g., (129) ]. 4 
Hz is also highly relevant for speech as it represents the peak modulation rate of the speech 
envelope modulation transfer function (130) . Temporal modulation threshold will be expressed in 
20 log m (dB), where m is the modulation index (0 to 1). For all tasks, cartoon images of an 
animal are time locked with the auditory stimulus and displayed on a touchscreen monitor. The 
child is asked to  identify which interval was “different” and responds via touchscreen display. We 
include auditory and visual feedback throughout the experiment with the goal of maintaining the 
child’s interest in the task. We have experience administering and interpretin g these tasks in this 
age range as discussed in Preliminary Studies . No prior study has described longitudinal auditory 
function for spectral, temporal, or spectrotemporal resolution in pediatric CI users in this age 
range within the context of an interven tion-based RCT.  
 We will also investigate spectral and temporal cue weighting using synthesized speech 
with word -initial voicing F0 and voice onset time (VOT). Both F0 and VOT can be used as reliable 
cues for voicing for word -initial stop consonants with V OT generally considered a more robust 
cue [e.g., (131) ]. However, research has shown that in the presence of signal degradation —such 
as with the in troduction of masking noise and/or low -pass filtering —greater weight may be 
placed on F0 [e.g., (132) ]. For CI recipients, F0 information is poorly transmitted with envelope -
based signal coding; hence in th e presence of background noise or very poor spectral resolution, 
it is unclear how effective CI recipients will be able to shift cue weighting from VOT to F0 and no 
such data exist for pediatric CI recipients, a group with poor spectral resolution. Thus we  will 
investigate speech perception outcomes by synthesizing a two -dimensional continuum varying 
both initial F0 and VOT. Synthesis will be accomplished using Praat by interpolating between a 
/pa/ and a /ba/ exemplar along each dimension. Exemplars in this  continuum will be presented to 
CI recipients and NH controls to quantify /pa/ -/ba/ classification. Responses from a control group 
of children with normal hearing will provide best -case speech perception in this continuum as 
well as estimates of the weight ing of cues on classification. This pediatric normative classification 
mapping will be used for comparison to pediatric CI recipients. These data will provide estimates 
of perceptual success as well as whether pediatric CI recipients are using different cu es and/or 
are able to re -weight cues.  
 Speech Recognition.  We will assess speech recognition in each CI ear alone as well as 
the bilateral aided condition (bilateral CI or CI plus contralateral hearing aid) including 
monosyllabic words, non -words, as well as sentences in quiet and co -located noise (+5 dB SNR) 
with speech presented at 60 dB SPL in quiet and 65 dB SPL in noise. We will use CNC (106)  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
monosyllables, non -word repetition tasks (114,133) , BabyBio sentences (107)  presented in quiet 
and at +5 dB SNR, as well as the  BKB-SIN test (108) . We will also obtain an adaptive speech 
receptive threshold for HINT sentences (134)  presented  at 0 degrees with semi -diffuse noise 
originating from 45 to 315 degrees as described in our previous publications (1,2). The semi -
diffuse noise will be fixed at 72 dB SPL [typical restaurant noise level (135,136) ] and the HINT 
sentences will be varied adaptively to yield 50% correct . CNC, BabyBio, and BKB -SIN are all 
recommended by the P ediatric Minimum Speech Test Battery (3) and thus hold high clinical 
relevance. Further, all measures have a sufficient number of lists allowing for longitudinal 
administrat ion without repetition.  We chose an SNR of +5 dB for fixed SNR assessment given 
that children aged 4.5-12 years spend ~80% of their day in noise including classrooms, school 
cafeterias, and playgrounds (137)  and +5 dB is  representative of the mean SNR encountered in 
everyday environments for elementary school -aged children (114-117). The additional measure 
of non -word repetition should be more sensitive to manipulations of IGCIP spatial selectivity and 
subsequent spectral resolution as non -words do not hold lexical meaning (114,139) . Despite the 
ubiquity of the speech recognition measures, there are no published data documenting the 
longitudinal performance trajectory for these measures of speech recognition and thus  these data 
offer high clinical value.  
We will use a SmartPhone app to assess word recognition at the baseline and 12 -month 
visits via Bluetooth or direct audio input. One month following baseline and 12 -month visits, a 
caregiver will re -administer this t est at home. In the event that word recognition has significantly 
declined relative to the immediately preceding visit —using 95% confidence intervals for test -
retest variability of word tasks (140) —we will offer the option of returning the  child to her 
previous CI map or giving an additional month with follow -up at the next scheduled appointment 
(at either 2 months or 14 months, per Table 3 ). Neither participant nor experimenter will not 
know whether the child is in the immediate IGCIP or w aitlist deferred group. Should the child be 
withdrawn from the study due to negative outcomes, this will require that we break the blind for 
a given participant (see Data Safety and Monitoring Plan ); however, we would continue to study 
auditory, speech, PA , language, and reading outcomes over a 2 -year period for this child. This 
will allow us to investigate underlying mechanisms responsible for those that are IGCIP 
responsive (estimated at over 75% of enrolled participants) as compared to non -responders —an 
important research question for clinical translation of this technology.   
 Subjective questionnaires (Auditory Skills & Quality of Life). We will  obtain 
subjective reports of auditory skills as well as overall quality of life for our pediatric participants 
using validated questionnaires: Auditory Skills Checklist [ASC (141) ], Parents’ Evaluation of 
Aural/oral performance of Children [PEACH (142) ], Vanderbilt Fatigue Scale .  
 Language Ability.  Language ability will be measured at two levels: expressive and 
receptive. Additionally, estimates of each domain will have multiple measures including  
vocabulary, morphology, and syntax. Receptive language abilities will be measured using the 
Receptive One -Word Picture Vocabulary Test -4 [ROWPVT -4 (144) ], Peabody Picture Vocabulary 
Test-4 [PPVT -4 (145) ], and the TACL -4 (146)  which includes se parate subscale scores for 
vocabulary, morphology, and elaborated sentences. The receptive composite of the Clinical 
Evaluation of Language Fundamentals -4 [CELF -4 (147) ] will also be administered to all 
participants. Expressive language will be measured using the Expressive One -Word Picture 
Vocabulary Test -4 [EOWPVT (148) ], the Structured Photographic Expressive Language Test -3 
[SPELT (149) ], and the expressive composite on the CELF -4 (147).  
 Speech production (standardized assessment and acoustic analyses). Because 
children with hearing loss potentially display clinical speech disorders as well as subclinical speech 
alterations that can be detected only within the context of acoustic a nalysis, we will complete 
both standardized clinical measures and acoustic analyses. Traditionally speaking, due to the 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
large amount of time spent on hand -analyses of speech production, a single dependent acoustic 
measure is chosen ‘a priori’. This is ofte n performed on a norm -referenced test of articulation 
such as the GFTA -3 (150) , which we plan to administer; however, we will also supplement the 
GFTA -3 with acoustic analyses of speech samples obtained at each visit. The value of an 
objective speech acoustic analysis is that a very large number of measures can be computed with 
no subjective input thereby allowing us to investigate acoustic measures, or clusters of acoustic 
measures, that are related to the independent variable, i.e. implementation of IGCIP. We audio 
record the administration of the Renfrew bus story (151)  as well as asking the child to repeat the 
Ling 6 sounds and “Twinkle Twinkle Little Star”. We will obtain these speech samples at baseline 
and all subsequent study visits ( Table 3 ). We will use Aural Analytics software (152)  to obtain 
automated measures of 1) vocal quality (i.e. harmonic -to-noise ratio), 2) pitch (F 0: mean, stdev , 
range), 3) articulatory control [articulatory  entropy (153) ]; the envelope modulation spectrum; 
formant frequencies for consonants and vowels, vowel space; long -term average spectrum; 
speaking rate), and, 4)  nasality (energy < 500 Hz).  The algorithm for m easuring articulation 
precision was calibrated using over 1000 hours of native English speech for adults and children 
and used to generate a normative distribution. In addition, we will manually investigate: a) 
differentiation between voiceless postalveola r affricates /ch/ and voiceless alveolar stop /t/ —
looking at peak amplitude and spectral mean of the fricative portions, b) differentiation of 
alveolar and postalveolar voiceless fricatives (/s/ vs /sh/), c) whole -word variability, and d) 
presence of atypi cal error patterns.  
Nonverbal assessment of cognition. Nonverbal cognition will be assessed using the 
3rd edition of the Leiter International Performance Scale [Leiter -3 (154) ]. This is a standardized 
nonverbal estimate of cognitive abilities and was successfully administered with the participants 
in our pilot studies. All participants must exhibit nonverbal cognitive abilities within the typical 
range for inclusion. Should we id entify a child exhibiting nonverbal cognitive abilities below the 
age-normative cutoff, we will refer to the developmental psychologist on the Vanderbilt CI Team.  
Working Memory.  Three tasks will be used: 1) Numbers Reversed from the Woodcock -
Johnson IV (155)  is a traditional test of memory span in which the child hears progressively 
longer strings of numbers a nd recalls in backwards order. Numbers will be audiorecorded with 
calibration and normalization of level (in dB SPL) for standardized auditory presentation across all 
participants and visits. Children will be asked to repeat each number prior to testing to  ensure 
accurate recognition. 2) A serial recall task will be used to assess one’s ability to use phonological 
structure to store words in a working memory buffer. This task has been used frequently, 
including pediatric CI users (75,76) . The child sits in front of a touchscreen monitor and hears a 
string of 6 non -rhyming consonant -vowel -consonant, high -frequency nouns. After presentation, 
pictures of the 6 items appear on the display and the child is asked to touch the pictures in the 
order  heard. The same 6 words are used across all trials and word recognition is confirmed both 
before and after testing. The serial recall task is used as it is more sensitive to phonological 
coding than free recall (156) . 3) A visual -spatial task will be used, to assess working memory in 
the absence of verbal material. In this task, the touchscreen monitor  is divided into 6 squares, 
and squares ill uminate one at a time. The child is asked to tap on the squares in the order 
recalled . Reasons for using all three tasks of working memory are as follows: 1) The 1st task is a 
standardized task and will provide standardized scores that can be interpreted a ccording to age 
norms and provide W scores, which are weighted raw scores that yield an estimate of ability level 
independent of age. 2) The 2nd task will assess children’s abilities to use phonological structure in 
service to verbal working memory. Resear ch has shown this task to be especially sensitive to 
differences in verbal working memory between children with NH who have typical language 
abilities and either children with CIs (referenced above) or children with NH, but phonological 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
deficits (157) . 3) The 3rd task will assess whether the participants have working memory deficits 
extending beyond simple verbal material.  
PA. As with speech and work ing memory, we include standardized measures of PA as 
well as additional in -depth measures (developed in consultation with Dr. Nittrouer). PA is defined 
as the ability to segment, discriminate, and operate on phonological units [speech sounds; see 
(158) ]. The Comprehensive Test Of Phonological Processing [CToPP -2 (159) ] is a norm -
referenced and widely used standardized assessment of this ability and in our preliminary study 
of PA in children with hearing loss (94). To obtain multiple standardized estimates of PA, we will 
also administer the  Test of Auditory Processing Skills [TAPS -3 (160) ]. Both of these tests have 
been used extensively in previous studies of PA including several with children with CIs (161) . In 
addition, Nittrouer and colleagues have developed an individualized set of tasks designed to 
provide an in -depth assessment of PA (8). They have argued that in parallel to subclinical 
alterations in speech production, specific aspects of PA may also illuminate the relationship 
between impoverished and/or altered access to the auditory CI signal and key aspects of P A. 
Because of this, in addition to the CToPP and the TAPS, we will also be administering the PA 
battery designed and studied in detail by Nittrouer including: Non -word Repetition, Initial 
Consonant Discrimination (Same -Different), Initial Consonant Choice,  Final Consonant Choice, 
Phoneme Deletion, and Backwards Words (21). Although many of these tasks are sub -items on 
the CToPP and/or the TAPS, the in -depth PA battery i ncludes multiple items that are 
developmentally ordered in each of these domains so that we can 1) accurately identify 
functional level for each skill at intake and 2) have sufficient sensitivity to capture short -term 
growth on one or more of these skills.  Because there has been considerable variability in the 
relationships between speech recognition and PA in this population, we hypothesize that the 
IGCIP data will yield insight into the relationship between speech recognition, PA, and reading 
ability as w ell as receptive language with a specific focus on bootstrapping of PA.  
Reading Ability.  Reading ability includes two key factors, decoding and reading 
comprehension (162) ; we will obtain multiple measures of each of these factors. St andardized 
tests include the Woodcock Reading Mastery Tests [WRMTTM-III (163) ] and the Gray Oral 
Reading Test -5 [GORT -5 (164) ]. Both instruments have been widely used with typically 
developing children and children with disabilities and, as with PA, have been applied to children 
with hearing loss in several studies. The WRMTTM-III includes decoding assessments (e.g., letter 
word identification) and assessment of reading comprehension (e.g., Passage comprehension). 
Similarly, the GORT -5 includes estimates of decoding and reading comprehension includ ing 
reading vocabulary comprehension and passage comprehension.  
Auditory Evoked Potentials (AEPs) . Auditory brainstem response (ABR) and 
Frequency Following Response (FFR) We will be presenting acoustic stimuli to the ears via insert 
earphones using a foa m eartip. The stimuli will either be click, tone, speech sound (such as /da/ 
sound), or a complex stimulus (such as a harmonic complex of pure tones that is amplitude 
modulated). The stimuli will be presented at a level of 70 dBnHL  that is consistent with raised 
speech levels encountered in everyday life. We will place surface electrodes on the participant's 
scalp (Cz), forehead (Fz), and earlobes (A1 & A2). The participant will be asked to sit quietly, 
relax, but to avoid excessive  blinking. The participant will be seated in a comfortable chair in a 
sound treated room. Breaks will be given as necessary. The AEP experiments will take 
approximately 30 to 40 minutes. AEP data will be analyzed following acquisition using MATLAB to 
extract timing and frequency information specify to the response  
Time -based description of assessments administered:  
BASELINE visit  (after consent and assent) :  
• Randomization to either immediate or waitlist deferred IGCIP  
• CI programming according to randomizat ion 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
• CI aided detection thresholds in the sound  field (250 -6000 Hz)  
• HA settings verification (for children with unilateral CI and HA in the non -CI ear)  
• Surveys administered to child and parent (ASC, PEACH, and Vanderbilt Fatigue Scale ) 
 
All baseline testing described below will be administered with the child’s original 
clinical program:  
o Speech recognition testing: CNC monosyllables, non -word repetition, BabyBio 
sentences in quiet, BabyBio sentences in multi -talker babble at +5 dB SNR 
(S0N0), BKB-SIN (S0N0), adaptive HINT in R -SPACETM system  NOTE: speech in 
quiet calibrated to 60 dB SPL, s peech in noise (S0N0) calibrated to 65 dB SPL, 
adaptive HINT in R -SPACETM noise calibrated to 72 dB SPL  
o Spectral resolution : spectral modulation detection for 0.5 and 1.0 cyc/oct  in 
sound field at 65 dB SPL, adaptive tracks  
o Temporal resolution: temporal modulation detection for rates of 4, 32, and 128 
Hz in sound field at 65 dB SPL, adaptive tracks  
o Spectrotemporal resolution: VOT & F0 exemplar recognition task  
o Language assessment: ROWPVT -4, PPVT-4, TACL -4, CELF -4, EOWPVT -4, SPELT -
3 (will be audio  & videorecorded)  
o Speech production assessment: GFTA -3, Renfrew bus story, and Twinkle Twinkle 
little star (will be audiorecorded)  
o Nonverbal cognitive assessment: Leiter -3 
o Working memory: Numbers Reversed from the Woodcock -Johnson IV, serial 
recall task, a nd visual -spatial task (will be audio and videorecorded)  
o Phonological awareness (PA): CToPP -2, TAPS-3, Non -word Repetition, Initial 
Consonant Discrimination (Same -Different), Initial Consonant Choice, Final 
Consonant Choice, Phoneme Deletion, and Backwards Words  
o Reading ability: WRMTTM-III and GORT -5 
o Auditory Evoked Potentials (AEPs): ABR and FFR  
 
Phone call  (1 month after baseline):  Experimenter will call  parent or primary 
caregiver to get information about the bluetooth administered word recognition task   
 
Visit 2 (2 months after baseline ):  
• CI aided detection thresholds in the sound  field (250 -6000 Hz)  
• HA settings verification (for children with unilateral CI and HA in the non -CI ear)  
• CI programming as needed (using the same assigned programming method)  
• Surveys administered to child and parent (ASC  and PEACH)  
• Speech recognition testing: CNC monosyllables, non -word repetition, BabyBio sentences 
in quiet, BabyBio sentences in multi -talker babble at +5 dB SNR (S0N0), BKB -SIN 
(S0N0), adaptive HINT in R -SPACETM system NOTE: speech in quiet calibrated to 60 dB 
SPL, speech in noise (S0N0) calibrated to 65 dB SPL, adaptive HINT in R -SPACETM noise 
calibrated to 72 dB SPL  
• Spectral resolution: spectral modulation detection for 0.5 and 1.0  cyc/oct in sound field 
at 65 dB SPL, adaptive tracks  
• Temporal resolution: temporal modulation detection for rates of 4, 32, and 128 Hz in 
sound field at 65 dB SPL, adaptive tracks  
• Spectrotemporal resolution: VOT & F0 exemplar recognition task  
 
Visit 3 (6 months after baseline) :  
• CI aided detection thresholds in the sound  field (250 -6000 Hz)  
• HA settings verification (for children with unilateral CI and HA in the non -CI ear)  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
• CI programming as needed (using the same assigned programming method)  
• Surveys administered to child and parent (ASC  and PEACH)  
• Speech recognition testing: CNC monosyllables, non -word repetition, BabyBio sentences 
in quiet, BabyBio sentences in multi -talker babble at +5 dB SNR (S0N0), BKB -SIN 
(S0N0), adaptive HINT in R -SPACETM system  NOTE: speech in quiet calibrated to 60 dB 
SPL, speech in noise (S0N0) calibrated to 65 dB SPL, adaptive HINT in R -SPACETM noise 
calibrated to 72 dB SPL  
• Spectral resolution: spectral modulation detection for 0.5 and 1.0 cyc/oct in sound field 
at 65 dB SPL,  adaptive tracks  
• Temporal resolution: temporal modulation detection for rates of 4, 32, and 128 Hz in 
sound field at 65 dB SPL, adaptive tracks  
• Spectrotemporal resolution: VOT & F0 exemplar recognition task  
 
 
Visit 4  (12 months after baseline) :  
• Participants  randomized to waitlist deferred IGCIP group will be programmed with IGCIP 
method (following assessments listed below)  
• CI aided detection thresholds in the sound  field (250 -6000 Hz)  
• HA settings verification (for children with unilateral CI and HA in the non -CI ear)  
• Surveys administered to child and parent (ASC, PEACH, and Vanderbilt Fatigue Scale ) 
 
All visit 4  testing described below will be administered with the child’s program 
that has been used up to this visit (i.e. not with any new programming changes 
made today)  
o Speech recognition testing: CNC monosyllables, non -word repetition, BabyBio 
sentences in quiet, BabyBio sentences in multi -talker babble at +5 dB SNR 
(S0N0), BKB -SIN (S0N0), adaptive HINT in R -SPACETM system NOTE: speech in 
quiet calibrated to 60 dB SPL, speech in noise (S0N0) calibrated to 65 dB SPL, 
adaptive HINT in R -SPACETM noise calibrated to 72 dB SPL  
o Spectral resolution: spectral modulation detection for 0.5 and 1.0 cyc/oct in 
sound field at 65 dB SPL, adaptive tracks  
o Temporal resolution: temporal modulation detection for rates of 4, 32, and 128 
Hz in sound field at 65 dB SPL, adaptive tracks  
o Spectrote mporal resolution: VOT & F0 exemplar recognition task  
o Language assessment: ROWPVT -4, PPVT -4, TACL -4, CELF -4, EOWPVT -4, SPELT -
3 (will be audio & videorecorded)  
o Speech production assessment: GFTA -3, Renfrew bus story, and Twinkle Twinkle 
little star (will be  audiorecorded)  
o Nonverbal cognitive assessment: Leiter -3 
o Working memory: Numbers Reversed from the Woodcock -Johnson IV, serial 
recall task, and visual -spatial task (will be audio and videorecorded)  
o Phonological awareness (PA): CToPP -2, TAPS -3, Non -word Rep etition, Initial 
Consonant Discrimination (Same -Different), Initial Consonant Choice, Final 
Consonant Choice, Phoneme Deletion, and Backwards Words  
o Reading ability: WRMTTM-III and GORT -5 
 
 
Phone call  (13 month s after baseline):  Experimenter will call  parent or primary 
caregiver to get information about the bluetooth administered word recognition task  
 
 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
Visit 5 (14 months after baseline) :  
• CI aided detection thresholds in the sound  field (250 -6000 Hz)  
• HA settings verification (for children with unilat eral CI and HA in the non -CI ear)  
• CI programming as needed (using the same assigned programming method)  
• Surveys administered to child and parent (ASC  and PEACH)  
• Speech recognition testing: CNC monosyllables, non -word repetition, BabyBio sentences 
in quiet,  BabyBio sentences in multi -talker babble at +5 dB SNR (S0N0), BKB -SIN 
(S0N0), adaptive HINT in R -SPACETM system NOTE: speech in quiet calibrated to 60 dB 
SPL, speech in noise (S0N0) calibrated to 65 dB SPL, adaptive HINT in R -SPACETM noise 
calibrated to 72 dB SPL  
• Spectral resolution: spectral modulation detection for 0.5 and 1.0 cyc/oct in sound field 
at 65 dB SPL, adaptive tracks  
• Temporal resolution: temporal modulation detection for rates of 4, 32, and 128 Hz in 
sound field at 65 dB  SPL, adaptive tracks  
• Spectrotemporal resolution: VOT & F0 exemplar recognition task  
 
 
Visit 6 (18 months after baseline) :  
• CI aided detection thresholds in the sound  field (250 -6000 Hz)  
• HA settings verification (for children with unilateral CI and HA in the non -CI ear)  
• CI programming as needed (using the same assigned programming method)  
• Surveys administered to child and parent (ASC  and PEACH)  
• Speech recognition testing: CNC monosyllables, non -word repetition, BabyBio sentences 
in quiet, BabyBio sentences  in multi -talker babble at +5 dB SNR (S0N0), BKB -SIN 
(S0N0), adaptive HINT in R -SPACETM system NOTE: speech in quiet calibrated to 60 dB 
SPL, speech in noise (S0N0) calibrated to 65 dB SPL, adaptive HINT in R -SPACETM noise 
calibrated to 72 dB SPL  
• Spectral resolution: spectral modulation detection for 0.5 and 1.0 cyc/oct in sound field 
at 65 dB SPL, adaptive tracks  
• Temporal resolution: temporal modulation detection for rates of 4, 32, and 128 Hz in 
sound field at 65 dB SPL, adaptive tracks  
• Spectrote mporal resolution: VOT & F0 exemplar recognition task  
 
 
Visit 7 (24 months after baseline):  
• CI aided detection thresholds in the sound field (250 -6000 Hz)  
• CI programming, as needed  
• HA settings verification (for children with unilateral CI and HA in the no n-CI ear)  
• Surveys administered to child and parent (ASC, PEACH, and Vanderbilt Fatigue Scale ) 
 
All visit 7 testing described below will be administered with the child’s program 
that has been used up to this visit (i.e. not with any new programming changes 
made today)  
o Speech recognition testing: CNC monosyllables, non -word repetition, BabyBio 
sentences in quiet, BabyBio  sentences in multi -talker babble at +5 dB SNR 
(S0N0), BKB -SIN (S0N0), adaptive HINT in R -SPACETM system NOTE: speech in 
quiet calibrated to 60 dB SPL, speech in noise (S0N0) calibrated to 65 dB SPL, 
adaptive HINT in R -SPACETM noise calibrated to 72 dB SPL  
o Spectral resolution: spectral modulation detection for 0.5 and 1.0 cyc/oct in 
sound field at 65 dB SPL, adaptive tracks  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
o Temporal resolution: temporal modulation detection for rates of 4, 32, and 128 
Hz in sound field at 65 dB SPL, adaptive tracks  
o Spectrotemporal resolution: VOT & F0 exemplar recognition task  
o Language assessment: ROWPVT -4, PPVT -4, TACL -4, CELF -4, EOWPVT -4, SPELT -
3 (will be audio & videorecorded)  
o Speech production assessment: GFTA -3, Renfrew bus story, and Twinkle Twinkle 
little star  (will be audiorecorded)  
o Nonverbal cognitive assessment: Leiter -3 
o Working memory: Numbers Reversed from the Woodcock -Johnson IV, serial 
recall task, and visual -spatial task (will be audio and videorecorded)  
o Phonological awareness (PA): CToPP -2, TAPS -3, Non -word Repetition, Initial 
Consonant Discrimination (Same -Different), Initial Consonant Choice, Final 
Consonant Choice, Phoneme Deletion, and Backwards Words  
o Reading ability: WRMTTM-III and GORT -5 
 
 
6.0 Reporting of Adverse Events or Unanticipated Problems invo lving Risk to 
Participants or Others  
 
The PIs and all study personnel will  comply with requirements regarding the reporting of adverse 
events (AEs), including plans for reporting of AEs to the IRB and appropriate regulatory agencies.  
AEs must be reported to the IRB within 10 working days after learning of the event or problem.  
 
7.0 Study Withdrawal/Discontinuation  
 
The investigation involves a new method of programming cochlear implants based on a 
comparison of pre - and post -operative CT scans. The risk to the patient is radiation exposure 
due to the postoperative CT scan; however, we complete postoperative scanning routinely for 
all CI recipients at VUMC (unless declined by the patient) given that the information gained by 
the scan and image processing has been determined by the Vanderbilt CI team to offer 
significant clinical value to the patient for CI programming optimization (e.g., identification of 
extracochlear electrodes, tip foldover).  Thus, this is NOT a risk to patients currently implanted 
at VUMC. Should a potential study participant not have a postoperative CT scan, 
s/he must be first consented and enrolle d in Dr. Labadie’s CT imaging study (IRB 
#090155 “Assessment of Electrode Placement and Audiologic Outcomes in 
Cochlear Implantation”) prior to consent and enrollment in the current study. For 
this reason, the current study has been linked to Dr. Labadie’s  study.  
 
The other portions of the research –namely deactivating CI electrodes –are within the scope of 
practice of audiologists for CI programming and thus utilize CI clinical software that is FDA 
approved and regulated. Oversight  for all study procedures will be provided  by the 
Vanderbilt’s Institutional Review Board and managed by the study PIs .  
 
If participants do not sign the consent form, no research data will be collected. Participants will 
leave with no negative consequences. If at any point, a participant indicates verbally that he/she 
no longer wants to continue with the study, he/she will N OT be forced to cooperate and he/she 
will be given the options of taking a break, discontinuing and rescheduling the session, or 
stopping participation in the study.  
 
No subject will be excluded from participation due to gender, race, or ethnicity. Cochle ar implant 
and hearing aid users will be drawn from the current patient population at Vanderbilt Bill 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
Wilkerson Center aged 4.5 to 12 years. The investigator(s) will be blind to race and ethnicity of 
participants prior to their actual date of participation . Thus, the same group of participants will 
benefit from the results of the research as those who will be participating.  
 
8.0 Privacy/Confidentiality Issues  
 
Discuss the methods for ensuring participant privacy, and the methods for protecting privacy and 
confidentiality.  
 
(Research, Activities, Procedures, and Schedule of Events for Study Participants - 
Describe the procedures that will be utilized to protect the privacy of the research 
participant.)  
 
Data will be entered and stored in REDCap.  
 
REDCap is a secure, web -based application that is flexible enough to be used for a variety of 
types of research. REDCap provides an intuitive user interface that streamlines project 
development and improves data  entry through real -time validation rules (with automated data 
type and range checks). REDCap also provides easy data manipulation (with audit trails for 
reporting, monitoring and querying patient records) and an automated export mechanism to 
common statis tical packages (SPSS, SAS, STATA, R/S -Plus).  
 
Audio and video recordings will be obtained of participants' spoken word responses to speech 
production and language assessment  tests for offline analysis of speech rate, formant frequency 
representation, and energy distribution of speech production. Audio recordings will be stored on 
a password protected, encrypted server hosted by the Vanderbilt Bi ll Wilkerson Center. The audio 
and video r ecordings will be labeled with a subject ID code and will not include n ame or any 
other identifying data.  
 
We will use paper case report forms (CRFs) to record data during experimentation. No identifying 
information will be placed on the CRFs. The CRFs along with signed informed consent forms will 
be stored in a locked file cabinet in the Cochlear Implant Research L aboratory (MCE South 
10326). Only the investigators and research assistants assigned to the project will have access to 
the REDCap databases as well as the locked file cabinet (all personnel will have completed 
human subjects training as well as good clinical practice training).  
 
(Research, Activities, Procedures, and Schedule of Events for Study - Describe how 
the confidentiality of participants' data will be assured. Include a description of any 
issues specific t o the study that might increase the risk of breach of confidentiality.)  
 
All appropriate measures will be taken to ensure the confidentiality of study participants. All data 
will be labeled and coded. These unique identification numbers will be used on all  source 
materials, including self -reported questionnaires, paper assessments, and computerized data. 
Data will be stored on secure, password -protected networked computers, in locked offices, and 
on dedicated REDCap database s. Only research staff will have access to participant data.  
 
A list linking names to identification numbers will be available only to authorized personnel for 
recruitment purposes. This will be kept on a password -protected roster stored on a secure server 
accessible only by the PI and her designees. Data will be destroyed  10 years following final study  
closure .  
 
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
The maintenance of all subject -relevant data will comply with the Health Insurance Portability 
and Accessibility Act (HIPAA), on which all lab personnel will be fully certified. Clinical information 
will be collected from patients' medical records by resea rchers with approved epic/estar  access.  
 
Prospec tive assign ment of  one or  more hu man subjec ts. All participants will receive 
intervention; however, half of the participants will be randomly assigned to immediate 
intervention and the other half will be assigned to the deferred intervention group using a waitlist 
control study design. Randomization to IGCIP or waitlist IGCIP will occur after written informed 
consent and will proceed in the same way for both testing periods. As described in the Approach, 
we will be using identical procedures for all participants regardless of arm to which they 
randomize including generation of an IGCIP plan, and longitudinal assessments performed by an 
audiologist and speech -language pathologist.  
 
A randomization schedule w ill be generated by Co -I and study statistician, Mary Dietrich, PhD, 
and provided to the PIs (Gifford and Camarata) prior to study commencement. To ensure equal 
numbers of participants in each arm, a computer -generated, permuted blocking algorithm (blocks 
of 4 participants) will be used to develop the schedule. The schedule will be password protected 
and saved on an encrypted server housed at the Vanderbilt Bill Wilkerson Center. As described in 
the Approach, we will be using identical procedures for all pa rticipants regardless of arm to which 
they randomize including (a) post -operative CT scanning  (if needed and completed per IRB 
#090155) , (b) generation of an IGCIP plan, and (c) longitudinal assessments performed by an 
audiologist and speech -language patho logist.  
 
Blinding.  Both the experimenters and the participants will be blinded. The experimenters will be 
notified of the randomization for a given participant on the day of the baseline visit.  Only the PIs 
and Co -I Dr. Dietrich, who will generate the randomization scheme, will know whether the 
participant is in the intervention or deferred waitlist group until the end of the study. Neither PI 
nor Dr. Dietrich will be personally administering assessments nor scoring tests for the 
participants.  
 
Provisions for breaking the b lind. To ensure that IGCIP does not impair auditory -only word 
recognition —an important ethical control in this clinical trial —we will use a SmartPhone app, 
(e.g., Hear Coach) to assess word recognition during the respective baseline as well as at 1 
month a nd 13 months following enrollment —as neither the participants nor the tester will know 
whether the subject is in the immediate or deferred intervention group. Words will be transmitted 
from the SmartPhone app via Bluetooth or direct audio input at a comfor table level. Study staff 
will administer the assessment at baseline; a caregiver will be asked to re -administer smartphone 
word task at home during the subsequent periods. In the event that word recognition has 
decreased relative to scores obtained during the previous study visit —using 95% confidence 
interval data for test -retest variability of word recognition tasks containing 25 items —we will offer 
the option of returning the child to a previous program or giving the child one additional month 
of study pa rticipation to be followed up at the regularly scheduled appointment for each group 
(Table 3). Note that it is possible that there will be some cases where no changes were made to 
the child's previous program for those in the deferred intervention. If no c hanges have been 
made to the child’s CI program —as in the case of the waitlist deferred group at the 1 -month post 
enrollment appointment —we would not expect changes in word recognition. However, should 
there be an aberrant/unexplained change in the child’s  hearing status and a change in word 
recognition without a change to the CI  
 
 
9.0 Follow -up and Record Retention  
Principal Investigator s: René Gifford, PhD & Stephen Camarata, PhD                       Date:  9/3/2021  
Study Title: Image -Guided Cochlear Implant Programming: Pediatric Speech, Language, and Literacy  
Institution/Hospital: VUMC  
 
List the duration of the study.  List the duration of record retention and the method for 
destruction or the possibility of indefinite archiving o f information.  
 
(Data and Safety - Provide a general description of the data and safety monitoring 
plan)  
 
In accordance with Vanderbilt guidelines and as outlined to the subjects in the consent form, the 
subjects' confidentiality will be ensured throughout  the study. All data will be identified by code 
numbers only and no description of individual patients will be included in any publication. Data 
obtained as part of this research will be maintained in PC computers accessible only to the 
investigators and r esearch staff that they designate. The data may be maintained for an 
indefinite period of time since scientific progress may indicate that new analyses be carried out 
on previously obtained data. Future studies/analyses will be carried out with approval of  the IRB. 
If paper records are to be destroyed, those containing subject identifiers will be shredded directly 
or transferred to the hospital's shredding service. If electronic data containing subject identifiers 
is to be destroyed, it will be disposed of using a medium -appropriate destruction method to 
prevent recovery. Data not containing subject identifiers will be disposed of by any convenient 
method.  