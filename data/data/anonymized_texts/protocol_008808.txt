 
   
 
STUDY PROTOCOL AND DATA ANALYSIS  
 
The Rewire Study (Mindfulness Mobile App to Reduce Adolescent Substance Use)  
 
Grant Number/Protocol ID :  1R43DA043288- 01 
Clinical Trials.gov ID: [STUDY_ID_REMOVED]  
Federal Award Date: 4/17/2017  
  
STUDY PROTOCOL  
We will conduct a pilot test of the My MUSE app with 60 high -risk adolescents who are involved in the juvenile justice 
system. Feasibility, usability, participant satisfaction, and pre-/post - intervention outcomes of substance use will be 
evaluated in the pilot study. Data on: 1) frequency and duration of app use, 2) number of modules completed, and 3) 
type and frequency of substance use pre - and post -intervention will be examined. Participants will be compensated using 
gift cards to Amazon in the following  increments: $20 for each of the baseline, 6 week and 3 -month assessments, and 
$25 bonus for completion off all three assessments.  Participants in the focus groups or usability testing will receive a $35  
gift card for their time and effort.  
Participants will include both male and female high risk adolescents recruited from the Department of Youth Services 
(DYS) in Lane County, Oregon. We have a long history of successful collaborations with the DYS, and have received their 
support for the current proposal . Inclusion criteria will be as follows: 1) ages 13 -17, 2) involvement with the juvenile 
justice system, 3) documented substance use, 4) English -speaking, and 5) living in the community (e.g., biological/ 
adoptive/foster parents). Twenty of these high-risk  adolescents will be recruited to participate in two focus groups to 
give us initial reactions to mockup of modules; five of these participants will also be asked to participate in preliminary 
usability testing of the first 4 modules of the MyMUSE app. Feedback from focus groups and preliminary usability testing 
will be used to inform adaptations to the app. The prototype app will then be evaluated in a pilot testing phase by having 
60 additional high -risk adolescents complete the 4 adapted treatment modules over the course of 6 weeks. Usability 
data, system log data on program use, and participant satisfaction data will be analyzed, and input gathered from participants will be used to inform additional features to be developed during Phase II. The primary o utcomes of the 
pilot -testing phase will be changes in adolescent substance use attitudes and behaviors measured at three time points: 
baseline, 6 weeks post -baseline (end of treatment), and three months post -baseline.    
Program navigation and usability wi ll be assessed during usability testing and for the evaluation participants over the 6 
weeks of use, and will include reports of: 1) ease of use, 2) perceived benefits of using the app, and 3) suggestions for 
product development and modifications. Particip ants will also provide ratings on product satisfaction and usability on a 
7-point Likert Scale. Qualitative data gathered from the focus groups will be recorded and evaluated with the goal of 
identifying challenges to using the app, product satisfaction, a nd suggested product modifications. This information will 
then be used to guide modifications for a Phase II SBIR application. In addition to qualitative data gathered during the 
pilot evaluation study, login tracking information from the app will be used to assess each participant’s: 1) frequency and 
duration of app use, 2) number of modules completed, and 3) type and frequency of substance use. These data will be used to evaluate treatment engagement and adherence, as well as to inform possible changes in substance use pre - and 
post -baseline.  
 The following measures will be used to examine changes in pre- and post - changes in substance use: 1) Alcohol and Drug 
Use Survey, 2) Adolescent Attitudes Questionnaire, and 3) Emotion Regulation Scale. The Alcohol and Drug Use Survey is 
a 48-item scale that combines the Michigan Alcohol Screening Test (MAST) and the Drug Abuse Screening Test (DAST) 
and the Self -Efficacy for Limiting Substance Use. These scales are widely used as measures to assess the level and 
frequency of alcohol and drug use, as well as the ability to limit substance use, and have been shown to have good 
psychometric properties. The Adolescent Attitudes Questionnaire is a measure of attitudes and beliefs regarding drug 
and alcohol that was adapted  from an interview developed to test 12 mediators of drug use in adolescents. For this 
study, we will use the normative beliefs, lifestyle incongruence, beliefs about consequences, and commitment scales. 
The Emotion Regulation Scale is a 36 -item self -repor t questionnaire designed to assess multiple aspects of emotion 
dysregulation. 
  
STATISTICAL ANALYSIS PLAN 
Outcome Evaluation. A three-panel, pre -, six week post -training, and three month follow -up design will be employed to 
assess the feasibility of the MyMUSE app. During this non -experimental trial phase, consumer satisfaction ratings will be 
assessed and recommendations for program modification will be solicited from the program participants. We will also 
examine system log files to assess participant eng agement in using the app (e.g., program components viewed, number 
of visits, and time of use). While the design does not control for potential threats to internal validity (i.e., extraneous factors), it will allow for the evaluation of the app with respect  to change on adolescent substance use attitudes and 
behaviors. Threats to internal validity will be addressed during a large– scale SBIR Phase -II randomized controlled trial 
comparing adolescents assigned the MyMUSE app versus a wait -list control group.  
Data analysis. Prior to analysis, all variables will be checked for out -of-range values and inter - and intra -measure 
consistency; frequency distributions and plots will be examined for unusual data distributions or data points. Any necessary data transforma tions will be employed. The main analysis will test the hypothesis that participants will show 
significant improvement in emotional and behavioral changes and attitudes and beliefs regarding substance use. We will 
use random coefficient growth models in a multilevel framework with individual variability in change in study outcomes 
from pretest to 3 -months nested within individuals. Following Singer and Willet [49] when constructing the longitudinal 
model we will (a) examine empirical growth plots; (b) fit a n unconditional means model; (c) fit an unconditional linear 
growth model; (d) fit unconditional non -linear models; and (e) compare models of longitudinal change from the previous 
two steps using the Akaike Information Criterion. To bolster our confidence in the internal validity of the non-experimental design, some ancillary analyses will be conducted. First, a dose-response analysis based on program system 
usage log files will be conducted to determine whether the amount of program use (e.g., program components viewed, 
number of visits, and time of use) is significantly associated with change in the outcome measures. Residual gain score 
analyses will be conducted using linear regression models to predict post -training and follow -up test scores in which the 
pre-training test scores will be included as a covariate. Second, we will test the hypothesis that participants who report 
greater satisfaction with the training app will have greater improvement in pre -training to post -training and follow -up 
scores using  residual gain score analysis. Finally, treating consumer satisfaction as a process variable, we will examine 
correlations between the satisfaction ratings and the amount of program use. To the extent that there is sufficient 
variability in program use and  consumer satisfaction, positive associations between these measures and change in pre- 
to post -training and follow -up scores will provide further support for the acceptability and effectiveness of the training 
app.    
Missing data. Missing data in outcome  measures may result from dropout or item non -response. The mixed -growth 
models described above make use of maximum likelihood estimates and allow for use of all available outcome data from all assessments, reducing bias and increasing power [50]. In gener al, maximum likelihood procedures, as well as 
imputation methods, will be used as they can provide unbiased estimates even in instances of substantial attrition [50 -
51]. Multiple imputation procedures will follow best -practice recommendations [52] and the observed and imputed data 
will be compared to ensure they show similar distributions [53].    
Power considerations. We rely on the fact that power from random coefficient growth models have been shown to surpass that of a mixed -model ANCOVA [54 -55]. We bas ed the power analysis on the mixed -model ANCOVA, thus 
providing a conservative estimate for random coefficients growth models. Based on a sample size of 60 participants, a two-tailed alpha at .05, a moderate correlation between pretest and posttest scores (R2 = .25) we have sufficient power 
(>.80) to detect moderately small effects or greater (d = .39). Analyses involving correlation coefficients will have adequate power to detect medium effects (r = .35).  