# Ilana Protocol Intelligence API Configuration Sample
# Copy this file to .env and configure your values

# === Core Analysis Configuration ===
ANALYSIS_MODE=simple
# Options: simple, hybrid, legacy
# - simple: Fast Azure AI processing only
# - hybrid: Combines simple + TA-enhanced processing  
# - legacy: Uses fallback processing methods

# === Azure AI Configuration ===
USE_SIMPLE_AZURE_PROMPT=true
# Use simplified Azure prompts for faster processing

# Azure OpenAI Credentials
AZURE_OPENAI_API_KEY=your_azure_openai_key_here
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
AZURE_OPENAI_API_VERSION=2024-02-01

# === RAG and Vector DB Configuration ===
RAG_ASYNC_MODE=true
# Controls synchronous RAG operations:
# - true: Refuse sync heavy RAG calls, return 202 queued or redirect to on-demand
# - false: Allow sync RAG (enterprise pilot only)

# Vector Database
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=ilana-medical-exemplars

# ChromaDB (Alternative)
CHROMA_PERSIST_DIRECTORY=./chroma_db
CHROMA_COLLECTION_NAME=medical_exemplars

# === TA (Therapeutic Area) Features ===
ENABLE_TA_ON_DEMAND=true
# Enable /api/generate-rewrite-ta endpoint for on-demand TA enhancement

ENABLE_TA_SHADOW=false
# Enable shadow worker for TA comparison studies
# Warning: Increases resource usage significantly

SHADOW_MAX_PER_MIN=30
# Shadow worker rate limit (requests per minute)

# === Text Processing Configuration ===
CHUNK_MAX_CHARS=3500
# Maximum characters per text chunk for processing

CHUNK_OVERLAP=200
# Character overlap between consecutive chunks

# === API Rate Limiting ===
RATE_LIMIT_PER_MINUTE=100
# API requests per minute per client

# === Database Configuration ===
DATABASE_URL=postgresql://username:password@localhost:5432/ilana_db
# PostgreSQL connection string for telemetry and job tracking

# Redis (for job queuing and caching)
REDIS_URL=redis://localhost:6379/0

# === Security Configuration ===
JWT_SECRET_KEY=your_jwt_secret_key_here
ADMIN_API_TOKEN=your_admin_token_with_min_20_chars

# === Logging Configuration ===
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

TELEMETRY_LOG_FILE=logs/telemetry.log
TELEMETRY_LOG_MAX_SIZE=50MB
TELEMETRY_LOG_BACKUP_COUNT=10

# === Server Configuration ===
HOST=0.0.0.0
PORT=8000
WORKERS=4

# Development flags
DEBUG=false
RELOAD=false

# === Integration Configuration ===
# PubMed BERT (for medical NER)
PUBMED_BERT_MODEL_PATH=microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract

# Transformers Cache
TRANSFORMERS_CACHE=./transformers_cache

# === Feature Flags ===
ENABLE_ASYNC_JOBS=true
# Enable async document processing endpoints

ENABLE_SSE_STREAMING=true  
# Enable Server-Sent Events for job progress

ENABLE_TELEMETRY=true
# Enable comprehensive telemetry logging

ENABLE_SHADOW_ADMIN_API=false
# Enable admin endpoints for shadow worker management